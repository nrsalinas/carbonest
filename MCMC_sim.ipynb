{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo uncertainty simulation\n",
    "\n",
    "Steps to propagate biomass uncertainty through Monte Carlo simulation. Based on the proposal by Réjou-Méchain et al., 2017, Methods in Ecology and Evolution 8:1163-1167 and implemented in the R package Biomass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to propagate biomass uncertainty through Monte Carlo simulation.\n",
    "\n",
    "1. Model tree diameter error. Could be normal distribution, parameters fitted from quality control measurements.  \n",
    "\n",
    "2. Model wood density error. Biomass uses a truncated normal distribution based on the absolute ranges recorded at the wood density database (0.08-1.39 g/ml). A better way could be based on ancestral range reconstructed on a seed plant phylogeny.\n",
    "\n",
    "3. Tree height error. Biomass takes a truncated normal distribution with the range(1.3-(maximum_height + 15)). However, this kind of error seems to by exponentially distributed, as it is more likely to record wrong values with taller trees. Parameters could be fitted with quality control measurements.\n",
    "\n",
    "4. Allometric equation uncertainty. Depending on the allometric equation employed, coefficient distributions are estimated. Biomass estimates a posterior distribution for each equation using a MCMCMC.\n",
    "\n",
    "5. Above ground biomass estimates are simulated for each tree n times using all the parameter distributions presented above, plus a random error. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc3\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample tree diameter and wood density uncertainty values\n",
    "diam = 35.0\n",
    "sdd = diam / 100.0\n",
    "diams = np.random.normal(diam, sdd, 100)\n",
    "\n",
    "wd = 0.5\n",
    "sdwd = 0.01\n",
    "wds = np.random.normal(wd, sdwd, 100)\n",
    "\n",
    "zip(diams,wds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load harvest data from Chave et al 2014\n",
    "har = pd.read_csv(\"../Chave_harvest_db/Chave_GCB_Direct_Harvest_Data.csv\")\n",
    "loc = pd.read_csv(\"../Chave_harvest_db/Localities.csv\")\n",
    "loc['Forest_type'] = loc.Forest_type.str.replace(' forest','')\n",
    "#print har.columns\n",
    "#print loc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def est_E(row):\n",
    "    #E = ( 0.178 × TS-0.938 × CWD-6.61× PS ) ×10 −3\n",
    "    ts = loc[loc.Abbreviation == row.Site]['Temp_Seasonality'].item()\n",
    "    cwd = loc[loc.Abbreviation == row.Site]['CWD_mm_yr'].item()\n",
    "    ps = loc[loc.Abbreviation == row.Site]['Precip_Seasonality_perc'].item()\n",
    "    E = (0.178 * ts - 0.938 * cwd - 6.61 * ps) * 1e-3\n",
    "    return E\n",
    "\n",
    "har['E'] = har.apply(est_E, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mymodel = pymc3.Model()\n",
    "trace = None\n",
    "with mymodel:\n",
    "    #Priors\n",
    "    a = pymc3.Normal('a', mu = -2.109, sd = 0.5)\n",
    "    b = pymc3.Normal('b', mu = -0.896, sd = 0.5)\n",
    "    c = pymc3.Normal('c', mu = 0.923, sd = 0.5)\n",
    "    d = pymc3.Normal('d', mu = 2.794, sd = 0.5)\n",
    "    e = pymc3.Normal('e', mu = -0.046, sd = 0.5)\n",
    "    sigma = pymc3.HalfNormal('sigma', sd=1)\n",
    "    \n",
    "    # Allometric equation Chave 2014\n",
    "    y_exp = a + b * har.E + c * np.log(har.Gravity) + d * np.log(har.DBH_cm) + e * np.log(har.DBH_cm)**2   \n",
    "        \n",
    "    # Likelihood function\n",
    "    Y_obs = pymc3.Normal('Y_obs', mu=y_exp, sd=sigma, observed=np.log(har.AGB_kg))\n",
    "    \n",
    "    # Metropolis kernel\n",
    "    #mstep = pymc3.Metropolis()\n",
    "    #trace = pymc3.sample(50000, njobs=4, step=mstep)\n",
    "    \n",
    "    # NUTS kernel is default option for continuous parameters\n",
    "    trace = pymc3.sample(5000, njobs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pymc3.diagnostics.effective_n(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pymc3.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pymc3.traceplot(trace)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
