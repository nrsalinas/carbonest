{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depuracion datos Inventario Forestal Nacional\n",
    "\n",
    "El presente notebook realiza la exploración inicial y depuración de datos del Inventario Forestal Nacional.\n",
    "\n",
    "**Módulos requeridos:** Numpy y Pandas para la depuración de datos, SQLAlchemy para la inserción de información en las bases de datos.\n",
    "\n",
    "Las siguientes variables indican la ubicación de las tablas de entrada en formato csv:\n",
    "\n",
    "1. `detritos`: Contiene los mediciones realizadas en detritos de madera.\n",
    "\n",
    "2. `ampie`: Mediciones de árboles muertos en pie.\n",
    "    \n",
    "3. `vegetacion`: Mediciones de árboles vivos.\n",
    "\n",
    "4. `generalInfo`: Informacion general de cada conglomerado\n",
    "\n",
    "5. `coordenadas`: Coordenadas de parcelas\n",
    "\n",
    "También es necesario indicar las credenciales de accesos al servidor MySQL a través de las variables `user` (nombre de usuario) y `password` (clave de acceso).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs as cd\n",
    "\n",
    "# Si se quieren realizar visualizaciones en las celdas:\n",
    "# %matplotlib inline\n",
    "\n",
    "# Si el script es ejecutado interactivamente (como un cuaderno Jupyter, por ejemplo)\n",
    "# la variable `interactive` debe ser `True`, de lo contrario los reportes de error\n",
    "# serán guardados en un archivo de texto (`logfile`).\n",
    "interactive = True\n",
    "\n",
    "# Archivo con reportes de error\n",
    "logfile = u\"revisar.txt\"\n",
    "\n",
    "logbuffer = u\"\"\n",
    "\n",
    "# MySQL user and password\n",
    "password = u\"\"\n",
    "user = u\"\"\n",
    "\n",
    "# Asignar nombres de archivos a variables\n",
    "#detritos = u\"../data/IFN/detritos.csv\"\n",
    "ampie =  u\"../../data_2018/amp_to_clean.csv\"\n",
    "vegetacion = u\"../../data_2018/veg_to_clean.csv\"\n",
    "#generalInfo = u\"../data/IFN/informacion_general/informacion_general.csv\"\n",
    "#coordenadas = u\"../data/IFN/informacion_general/coordenadas.csv\"\n",
    "#analizador = u\"../data/IFN/suelos/analizador.csv\"\n",
    "#carbono = u\"../data/IFN/suelos/carbono.csv\"\n",
    "#fertilidad = u\"../data/IFN/suelos/fertilidad.csv\"\n",
    "\n",
    "# Leer archivos como Pandas dataframes\n",
    "#det = pd.read_csv(detritos, encoding = 'utf8') \n",
    "#amp = pd.read_csv(ampie, encoding = 'utf8')\n",
    "veg = pd.read_csv(vegetacion, encoding = 'utf8')\n",
    "#info = pd.read_csv(generalInfo, encoding = 'utf8')\n",
    "#coord = pd.read_csv(coordenadas, encoding = 'utf8')\n",
    "#analiz = pd.read_csv(analizador, encoding = 'utf8')\n",
    "#carb = pd.read_csv(carbono, encoding = 'utf8')\n",
    "#fert = pd.read_csv(fertilidad, encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vegetacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONS = u\"Cons\" # Indice de medicion comun con arboles muertos en pie (int)\n",
    "PLOT = u\"Plot\" # Indice conglomerado (int)\n",
    "SPF = u\"Spc\" # Indice subparcela (int 1-5)\n",
    "IND = u\"Ind\" # Indice de individuo en el conglomerado (int)\n",
    "TAMANO = u\"Tamano\" # Tamaño del individuo (str: 'L', 'F', o 'FG')\n",
    "AZIMUT = u\"Azimut\" # Orientacion del individuo desde el centro de la subparcela (int, 0-360)\n",
    "DIST = u\"Dist\" # Distancia en m del individuo al centro de la parcela (float, 0-15.74)\n",
    "DAP1 = u\"Dap1\" # Primer diámetro estimado del tallo en cm (float)\n",
    "DAP2 = u\"Dap2\" # Segundo diámetro estimado del tallo en cm (float)\n",
    "DAPA = u\"Dapa\" # Diametro promedio del tallo en cm (float)\n",
    "ALTF = u\"Altf\" # Altura fuste en m (float)\n",
    "ALTT = u\"Altt\" # Altura total en m (float)\n",
    "FAMILIA = u\"Familia\" # Familia taxonomica (str)\n",
    "GENERO = u\"Genero\" # Genero taxonomico (str)\n",
    "EPITETO = u\"Epiteto\" # Epiteto taxonomico (str)\n",
    "#AUTOR = u\"AUTOR\" # Autor taxonomico (str)\n",
    "#ESPECIE = u\"ESPECIE\" # Binomio taxonomico (str)\n",
    "#DENS = u\"DENS\" # Densidad de la madera en gr/ml (float)\n",
    "#FUENTE_DENSIDAD = u\"FUENTE_DENSIDAD\" # Referencia bibliografica de la densidad de la madera (str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logbuffer = u\"\\n\" + u\"#\" * 50 + u\"\\nTABLA VEGETACION\\n\"\n",
    "for fi in [CONS, PLOT, SPF, IND]:\n",
    "    if veg[fi].dtype != np.int64:\n",
    "        logbuffer += u\"\\nCampo {0} tiene tipo inapropiado ({1} en vez de int64).\\n\".format(\n",
    "            fi, veg[fi].dtype)\n",
    "        if len(veg[fi][det[fi].isna()]) > 1:\n",
    "            logbuffer += u\"\\nValores nulos son considerados np.float64:\\n\"\n",
    "            logbuffer += veg[[CONS, fi, PLOT, SPF]][veg[fi].isna()].join(info[['PLOT',\n",
    "                            'SOCIO']].set_index(PLOT), on=PLOT, rsuffix='_info').to_string(\n",
    "                            index = False) + \"\\n\"\n",
    "        else:\n",
    "            logbuffer += u\"\\nValores np.float64 a revisar:\\n\"\n",
    "            logbuffer += veg[CONS, fi, PLOT, SPF][veg[fi].map(lambda x: x % 1.0 != 0)].dropna(\n",
    "                            ).merge(info[['PLOT', 'SOCIO']], on=PLOT).to_string(index = False\n",
    "                            ) + \"\\n\"\n",
    "            \n",
    "        \n",
    "for fi in [AZIMUT, DIST, DAP1, DAP2, ALTT, ALTF]:\n",
    "    if veg[fi].dtype != np.float64:\n",
    "        logbuffer += u\"\\nCampo {0} tiene tipo inapropiado ({1}en vez de float64).\\n\".format(\n",
    "            fi, veg[fi].dtype)\n",
    "\n",
    "for fi in [FAMILIA, GENERO, EPITETO, TAMANO]:\n",
    "    non_strings = veg[fi].dropna()[~veg[fi].dropna().apply(type).eq(unicode)]\n",
    "    if len(non_strings):\n",
    "        logbuffer += u\"\\nCampo {0} tiene tipo inapropiado ({1} en vez de unicode).\\n\".format(\n",
    "            fi, non_strings.dtype)\n",
    "\n",
    "if interactive:\n",
    "    print logbuffer \n",
    "    logbuffer = u\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "veg[veg[CONS].duplicated(keep=False)].sort_values(\"Cons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if len(veg[veg[CONS].duplicated()]):\n",
    "    logbuffer += u\"\\nTabla {0} contiene indices duplicados.\\n\".format(vegetacion)\n",
    "    \n",
    "    to_drop = veg[veg[CONS].duplicated(keep=\"first\")].index.tolist()\n",
    "    \n",
    "    veg.drop(to_drop, inplace=True)\n",
    "\n",
    "for spf in veg[SPF].unique():\n",
    "    if spf not in range(1,6):\n",
    "        logbuffer += u\"\\nValor no valido de parcela: {0}\\n\".format(spf)\n",
    "\n",
    "veg[TAMANO] = veg[TAMANO].str.upper()\n",
    "for tam in veg[TAMANO].unique():\n",
    "    if tam not in [u'B', u'L', u'F', u'FG']:\n",
    "        logbuffer += u\"\\nValor no valido de tamaño de individuo: {0}\\n\".format(tam)\n",
    "        \n",
    "if veg[AZIMUT].min() < 0:\n",
    "    logbuffer += u\"\\nAzimut contiene valores no aceptados.\\n\"\n",
    "\n",
    "if veg[AZIMUT].max() > 360:\n",
    "    logbuffer += u\"\\nAzimut contiene valores no aceptados.\\n\"\n",
    "    \n",
    "    veg.loc[veg[AZIMUT] > 360, AZIMUT] = 360\n",
    "    \n",
    "# Verificar asignacion de clases diametricas\n",
    "veg[\"Dapa\"] = veg[[\"Dap1\", \"Dap2\"]].mean(axis=1)\n",
    "if len(veg[(veg[TAMANO] != u'B') & (veg[DAPA] < 2.5)]):\n",
    "\n",
    "    logbuffer += u\"\\nBrinzales están asignados a categoria erronea:\\n\"\n",
    "\n",
    "    logbuffer += veg[[CONS, PLOT, SPF, TAMANO, DAP1, DAP2]][(veg[TAMANO] != u'B') \n",
    "                    & (veg[DAPA] < 2.5)].to_string(index=False) + \"\\n\"\n",
    "\n",
    "    veg.loc[(veg[TAMANO] != u'B') & (veg[DAPA] < 2.5), TAMANO] = u'B'\n",
    "    \n",
    "if len(veg[(veg[TAMANO] != u'L') & (veg[DAPA] < 10) & (veg[DAPA] >= 2.5)]):\n",
    "    \n",
    "    logbuffer += u\"\\nLatizales están asignados a categoria erronea:\\n\"\n",
    "    \n",
    "    logbuffer += veg[[CONS, PLOT, SPF, TAMANO, DAP1, DAP2]][(veg[TAMANO] != u'L') \n",
    "        & (veg[DAPA] < 10) & (veg[DAPA] >= 2.5)].to_string(index= False) + \"\\n\"\n",
    "    \n",
    "    veg.loc[(veg[TAMANO] != u'L') & (veg[DAPA] < 10) & (veg[DAPA] >= 2.5), TAMANO] = u'L'\n",
    "    \n",
    "if len(veg[(veg[TAMANO] != u'F') & (veg[DAPA] < 30) & (veg[DAPA] >= 10)]):\n",
    "    \n",
    "    logbuffer += u\"\\nFustales están asignados a categoria erronea:\\n\"\n",
    "    \n",
    "    logbuffer += veg[[CONS, PLOT, SPF, TAMANO, DAP1, DAP2]][(veg[TAMANO] != u'F') & \n",
    "        (veg[DAPA] < 30) & (veg[DAPA] >= 10)].to_string(index=False) + \"\\n\"\n",
    "    \n",
    "    veg.loc[(veg[TAMANO] != u'F') & (veg[DAPA] < 30) & (veg[DAPA] >= 10), TAMANO] = u'F'\n",
    "    \n",
    "if len(veg[(veg[TAMANO] != u'FG') & (veg[DAPA] >= 30)]):\n",
    "    \n",
    "    logbuffer += u\"\\nFustales grandes están asignados a categoria erronea:\\n\"\n",
    "    \n",
    "    logbuffer += veg[[CONS, PLOT, SPF, TAMANO, DAP1, DAP2]][(veg[TAMANO] != u'FG') \n",
    "        & (veg[DAPA] >= 30)].to_string(index = False) + \"\\n\"\n",
    "    \n",
    "    veg.loc[(veg[TAMANO] != u'FG') & (veg[DAPA] >= 30), TAMANO] = u'FG'\n",
    "    \n",
    "# Eliminar individuos sin informacion necesaria para asignar clase diametrica\n",
    "veg.drop(veg[~veg[TAMANO].isin([u'B', u'L', u'F', u'FG'])].index, inplace = True)\n",
    "\n",
    "# Verificar si las distancias corresponden a las categorias de edad.\n",
    "# Latizales y Fustales afuera de su area de medición son eliminados\n",
    "if len(veg[(veg[DIST] > 3) & (veg[TAMANO] == u'L')]):\n",
    "    \n",
    "    logbuffer += u\"\\nLatizales registrados afuera del area aceptada:\\n\"\n",
    "    \n",
    "    logbuffer += veg[[CONS, TAMANO, DIST, PLOT, SPF]][(veg[DIST] > 3) & (veg[TAMANO] == u'L')\n",
    "        ].to_string(index=False) + \"\\n\"\n",
    "    \n",
    "    veg.drop(veg[(veg[DIST] > 3) & (veg[TAMANO] == u'L')].index, inplace=True)\n",
    "    \n",
    "if len(veg[(veg[DIST] > 7) & (veg[TAMANO] == u'F')]):\n",
    "    \n",
    "    logbuffer += u\"\\nFustales registrados afuera del area aceptada:\\n\"\n",
    "    \n",
    "    logbuffer += veg[[CONS, TAMANO, DIST, PLOT, SPF]][(veg[DIST] > 7) & (veg[TAMANO] == u'F')\n",
    "        ].to_string(index=False) + \"\\n\"\n",
    "    \n",
    "    veg.drop(veg[(veg[DIST] > 7) & (veg[TAMANO] == u'F')].index, inplace=True)\n",
    "    \n",
    "if len(veg[veg[DIST] > 15]):\n",
    "    \n",
    "    logbuffer += u\"\\nIndividuos registrados afuera del area de la subparcela:\\n\"\n",
    "    \n",
    "    logbuffer += veg[[CONS, TAMANO, DIST, PLOT, SPF]][veg[DIST] > 15].to_string(index=\n",
    "                    False) + \"\\n\"\n",
    "    \n",
    "    veg.drop(veg[veg[DIST] > 15].index, inplace = True)\n",
    "\n",
    "# Altura total siempre debe ser mayor a la altura del fuste\n",
    "if veg[veg[ALTF] > veg[ALTT]].size:\n",
    "    \n",
    "    logbuffer += u\"\\nIndividuos con altura del fuste mayor a la altura total:\\n\"\n",
    "    \n",
    "    logbuffer += veg[[CONS, ALTF, ALTT, PLOT, SPF]][veg[ALTF] > veg[ALTT]].to_string(index\n",
    "                    =False) + \"\\n\"\n",
    "    \n",
    "    indexes = veg[veg[ALTF] > veg[ALTT]].index\n",
    "    myaltt = veg.loc[indexes, ALTT].copy()\n",
    "    veg.loc[indexes, ALTT] = veg.loc[indexes, ALTF]\n",
    "    veg.loc[indexes, ALTF] = myaltt\n",
    "    \n",
    "#################################################\n",
    "# Que hacer con brinzales de altura mayor a 1 m?\n",
    "# Brinzales de altura menor a 30 cm o 0?\n",
    "#################################################\n",
    "# Altura de brinzales deben ser menores a 2 m\n",
    "veg.loc[(veg[TAMANO] == u'B') & (veg[ALTT] > 10), ALTT] /= 100.0\n",
    "veg.loc[(veg[TAMANO] == u'B') & (veg[ALTT] > 2), ALTT] /= 10.0\n",
    "\n",
    "# Verificar determinaciones incongruentes entre tallos de individuos multiples\n",
    "indsppcount = veg.groupby([PLOT,SPF,IND, GENERO, EPITETO]).size().reset_index()\n",
    "indcount = indsppcount.groupby([PLOT,SPF,IND]).size().reset_index().rename(columns={0:u'size'})\n",
    "if len(indcount[indcount[u'size'] > 1]):\n",
    "    \n",
    "    logbuffer += u\"\\nIndividuos de tallos multiples con determinaciones de varias especies:\\n\"\n",
    "    \n",
    "    logbuffer += indcount[indcount[u'size'] > 1].to_string(index = False) + u\"\\n\"\n",
    "\n",
    "\n",
    "\n",
    "if interactive:\n",
    "    print logbuffer \n",
    "else:\n",
    "    with cd.open(logfile, mode='a', encoding=\"utf-8\") as fhandle:\n",
    "        fhandle.write(logbuffer)\n",
    "logbuffer = u\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informacion general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONS = u'CONS' # Indice informacion (int64)\n",
    "PLOT = u'PLOT' # Indice conglomerado (int64)\n",
    "DEPARTAMENTO = u'DEPARTAMENTO' # Departamento (str)\n",
    "REGION = u'REGION' # Region biogeografica (str: 'Amazonia', 'Andes', 'Pacifico', 'Orinoquia', 'Caribe')\n",
    "FECHA_CAMPO = u'FECHA_CAMPO' # Año de toma de datos (int64)\n",
    "SOCIO = u'SOCIO' # Institucion que ejecuta el levantamiento de datos (str: 'Sinchi', 'IAvH', 'IIAP')\n",
    "BOT_TOT = u'BOT_TOT' # ???????????????? (str: 'Si', 'No'). Deberia ser boolean.\n",
    "CARB = u'CARB' # Estimacion de carbono ????? (str: 'Si', 'No'). Deberia ser boolean.\n",
    "SPFC = u'SPF-C' # En cuantas parcelas se tomaron datos de carbono (int64 0-5)\n",
    "FERT = u'FERT' # Estimacion fertilidad (str: 'Si', 'No'). Deberia ser boolean.\n",
    "DETR = u'DETR' # Toma de detritos (str: 'Si', 'No'). Deberia ser boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logbuffer = u\"\\n\" + u\"#\" * 50 + u\"\\nTABLA INFORMACION GENERAL\\n\"\n",
    "# Verificar el tipo de dato an cada campo de la tabla informacion general\n",
    "for fi in [CONS, PLOT, FECHA_CAMPO, SPFC]:\n",
    "    if info[fi].dtype != np.int64:\n",
    "        logbuffer += u\"\\nCampo {0} tiene tipo inapropiado ({1} en vez de int64).\\n\".format(fi, veg[fi].dtype)\n",
    "        if len(info[fi][det[fi].isna()]) > 1:\n",
    "            logbuffer += u\"\\nValores nulos son considerados np.float64:\\n\"\n",
    "            logbuffer += info[[fi, PLOT, SOCIO]][det[fi].isna()].to_string()\n",
    "        else:\n",
    "            logbuffer += u\"\\nValores np.float64 a revisar:\\n\"\n",
    "            logbuffer += info[fi][info[fi].map(lambda x: x % 1.0 != 0)].dropna().to_string()\n",
    "            \n",
    "for fi in [DEPARTAMENTO, REGION, SOCIO]:\n",
    "    non_strings = info[fi].dropna()[~info[fi].dropna().apply(type).eq(unicode)]\n",
    "    if len(non_strings):\n",
    "        logbuffer += u\"\\nCampo {0} tiene tipo inapropiado ({1} en vez de unicode).\\n\".format(fi, non_strings.dtype)\n",
    "\n",
    "#########################################################\n",
    "# Se asume que los campos BOT_TOT, fertilidad y detritos \n",
    "# son boolean en vez de texto\n",
    "#########################################################\n",
    "try:\n",
    "    info[BOT_TOT].replace(to_replace = [u'Si', u'No'], value = [True, False], inplace = True)\n",
    "    info[FERT].replace(to_replace = [u'Si', u'No'], value = [True, False], inplace = True)\n",
    "    info[DETR].replace(to_replace = [u'Si', u'No'], value = [True, False], inplace = True)\n",
    "    info[CARB].replace(to_replace = [u'Si', u'No'], value = [True, False], inplace = True)\n",
    "except TypeError, ErrorMessage:\n",
    "    if ErrorMessage.args[0] == \"Cannot compare types 'ndarray(dtype=bool)' and 'unicode'\":\n",
    "        pass\n",
    "except:\n",
    "    raise\n",
    "    \n",
    "for fi in [BOT_TOT, DETR, FERT, CARB]:\n",
    "    if info[fi].dtype != np.bool:\n",
    "        logbuffer += u\"\\nCampo {0} tiene tipo inapropiado ({1} en vez de np.bool).\\n\".format(fi, veg[fi].dtype)\n",
    "        \n",
    "if interactive:\n",
    "    print logbuffer \n",
    "    logbuffer = u\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Verificar rango de datos\n",
    "if len(info[info[CONS].duplicated()]):\n",
    "    logbuffer += u\"\\nTabla {0} contiene indices duplicados.\\n\".format(generalInfo)\n",
    "\n",
    "for spf in info[SPFC].unique():\n",
    "    if spf not in range(1,6):\n",
    "        logbuffer += u\"\\nValor no valido de parcela: {0}\\n\".format(spf)\n",
    "        logbuffer += info[[PLOT, SPFC, SOCIO]][info[SPFC] == spf].to_string(index = False)\n",
    "        info.drop(info[info[SPFC] == spf].index, inplace=True)\n",
    "\n",
    "if len(info[info[DETR].isna() | info[CARB].isna() | info[BOT_TOT].isna() | info[FERT].isna()]):\n",
    "    logbuffer += u\"\\nDatos faltantes en columna Detritos, Carbono, Fertilidad o BOT_TOT:\\n\"\n",
    "    logbuffer += info[[DETR, CARB, BOT_TOT, FERT, PLOT, SPFC, SOCIO]][info[DETR].isna() | \n",
    "                    info[CARB].isna() | info[BOT_TOT].isna() | info[FERT].isna()].to_string(\n",
    "                    index=False)\n",
    "        \n",
    "if interactive:\n",
    "    print logbuffer \n",
    "else:\n",
    "    with cd.open(logfile, mode='a', encoding=\"utf-8\") as fhandle:\n",
    "        fhandle.write(logbuffer)\n",
    "logbuffer = u\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árboles muertos en pie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONS = u'CONS' # Indice de medicion comun con arboles en pie (int64)\n",
    "PLOT = u'PLOT' # Indice conglomerado (int64)\n",
    "SPF = u'SPF' # Indice subparcela (int64)\n",
    "TAMANO = u'TAMANO' # Tamaño del individuo (str: 'L', 'F', o 'FG')\n",
    "IND = u'IND' # Indice de individuo en el conglomerado (int64)\n",
    "COND = u'COND' # Condicion del individuo (str, 'MP', 'TO', 'VP', 'MC', 'M'). Valores TO, MC y M no estan consignados en el manual del INF. Que hacen individuos vivos (VP) en esta tabla?????\n",
    "AZIMUT = u'AZIMUT' # Orientacion del individuo desde el centro de la subparcela (int, 0-360)\n",
    "DIST = u'DIST' # Distancia en m del individuo al centro de la parcela (float, 0-15.74)\n",
    "DAP_EQUIPO = u'DAP_EQUIPO' # Equipo empleado en la medicion de DAP (str: 'CD', 'FO', 'CA', 'CM'). Cuales son CM y CD? No estan especificados en el manual del INF.\n",
    "DAP1 = u'DAP1' # Primer diámetro estimado del tallo en cm (float64)\n",
    "DAP2 = u'DAP2' # Segundo diámetro estimado del tallo en cm (float64)\n",
    "DAPA = u'DAPA' # Diametro promedio del tallo en cm (float64)\n",
    "POM = u'POM' # Punto de observacion de la medida en m (float64). Hay medidas en cm.\n",
    "ALT_EQUIPO = u'ALT_EQUIPO' # Equipo usado en la medicion de la altura (str: 'HI', 'VT', 'CL', 'CM', 'VX', 'FL', 'CD'). Valores 'CM', 'VX', 'FL' y 'CD' no esta especificados en el manual del INF.???????????????????\n",
    "ALTF = u'ALTF' # Altura fuste en m (float)\n",
    "ALTT = u'ALTT' # Altura total en m (float)\n",
    "FORMA_FUSTE = u'FORMA_FUSTE' # (str: 'CIL', 'RT','IRR','FA','HI','Q'). Clases de valores estan repetidos por insercion de espacios o uso de minusculas. Valores 'HI' y 'Q' no estan consignados en el manual del INF. ??????????\n",
    "DANO = u'DANO' # Daño registrado (str: 'Q', 'DB', 'SD', 'DM', 'IRR', 'EB'). Valor 'IRR' no esta consignado en el manual del INF.?????\n",
    "PI_cm = u'Pi_cm' # Penetracion del penetrometro en cm (float64).\n",
    "PI_golpes = u'Pi_golpes' # Golpes ejecutados con el penetrometro (float64). Por que es un numero real????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logbuffer = u\"\\n\" + u\"#\" * 50 + u\"\\nTABLA ARBOLES MUERTOS EN PIE\\n\"\n",
    "for fi in [CONS, PLOT, SPF, IND, AZIMUT]:\n",
    "    if amp[fi].dtype != np.int64:\n",
    "        logbuffer += u\"\\nCampo {0} tiene tipo inapropiado ({1} en vez de int64).\\n\".format(\n",
    "                        fi, amp[fi].dtype)\n",
    "        if len(amp[fi][amp[fi].isna()]) > 1:\n",
    "            logbuffer += u\"\\nLos siguentes valores nulos son considerados np.float64 por Pandas:\\n\"\n",
    "            logbuffer += amp[[fi, PLOT, SPF]][amp[fi].isna()].merge(info[[PLOT, SOCIO]], \n",
    "                            on=PLOT, how='left').to_string(index=False)\n",
    "        else:\n",
    "            logbuffer += u\"\\nValores np.float64 a revisar:\\n\"\n",
    "            logbuffer += amp[[fi, PLOT, SPF]][amp[fi].map(lambda x: x % 1.0 != 0)].dropna().merge(\n",
    "                            info[[PLOT, SOCIO]], on=PLOT, how='left').to_string(index=False)\n",
    "            \n",
    "for fi in [DIST, DAP1, DAP2, DAPA, POM, ALTF, ALTT, PI_cm, PI_golpes]:\n",
    "    if amp[fi].dtype != np.float64:\n",
    "        logbuffer += u\"\\nCampo {0} tiene tipo inapropiado ({1} en vez de float64)\\n.\".format(\n",
    "                        fi, amp[fi].dtype)\n",
    "        \n",
    "        \n",
    "for fi in [TAMANO, COND, DAP_EQUIPO, ALT_EQUIPO, FORMA_FUSTE, DANO]:\n",
    "    non_strings = amp[fi].dropna()[~amp[fi].dropna().apply(type).eq(unicode)]\n",
    "    if len(non_strings):\n",
    "        logbuffer += u\"\\nCampo {0} tiene tipo inapropiado ({1} en vez de unicode).\\n\".format(\n",
    "                        fi, non_strings.dtype)\n",
    "\n",
    "if interactive:\n",
    "    print logbuffer \n",
    "    logbuffer = u\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if len(amp[amp[CONS].duplicated()]):\n",
    "\n",
    "    logbuffer += u\"\\nTabla {0} contiene indices duplicados.\\n\".format(ampie)\n",
    "\n",
    "vym = pd.concat( [veg[CONS],amp[CONS]]) # Indices de vivos y muertos en pie\n",
    "\n",
    "if len(vym[vym.duplicated()]):\n",
    "    \n",
    "    logbuffer += u\"\\nExisten indices duplicados en las tablas {0} y {1}.\\n\".format(veg, ampie)\n",
    "\n",
    "for spf in amp[SPF].unique():\n",
    "    \n",
    "    if spf not in range(1,6):\n",
    "        \n",
    "        logbuffer += u\"\\nValor no valido de parcela: {0}\\n\".format(spf)\n",
    "        \n",
    "        logbuffer += amp[[SPF, PLOT]][amp[SPF] == spf].merge(info[[PLOT, SOCIO]], \n",
    "                        on=PLOT, how='left').to_string(index=False) + u\"\\n\"\n",
    "        \n",
    "        amp.drop(amp[amp[SPF] == spf].index, inplace=True)\n",
    "\n",
    "for tam in amp[TAMANO].unique():\n",
    "    \n",
    "    if tam not in [u'L', u'F', u'FG']:\n",
    "        \n",
    "        logbuffer += u\"\\nValor no valido de tamaño de individuo: {0}\\n\".format(tam)\n",
    "        \n",
    "if amp[AZIMUT].min() < 0:\n",
    "\n",
    "    logbuffer += u\"\\nAzimut contiene valores no aceptados.\\n\"\n",
    "\n",
    "if amp[AZIMUT].max() > 360:\n",
    "\n",
    "    logbuffer += u\"\\nAzimut contiene valores no aceptados.\\n\"\n",
    "    \n",
    "# Verificar asignacion de clases diametricas\n",
    "if len(amp[(amp[TAMANO] != u'B') & ((amp[DAPA] < 2.5) | ((amp[DAP1] + amp[DAP2]) < 5.0))]):\n",
    "\n",
    "    logbuffer += u\"\\nBrinzales están asignados a categoria erronea:\\n\"\n",
    "\n",
    "    logbuffer += amp[[PLOT, SPF, TAMANO, DAPA, DAP1, DAP2]][(amp[TAMANO] != u'B') & \n",
    "                    ((amp[DAPA] < 2.5) | ((amp[DAP1] + amp[DAP2]) < 5.0))].join(info[[u'PLOT', \n",
    "                    u'SOCIO']].set_index(PLOT), on=PLOT, rsuffix=u'_info').to_string(index=\n",
    "                    False) + u\"\\n\"\n",
    "    \n",
    "    amp.loc[(amp[TAMANO] != u'B') & ((amp[DAPA] < 2.5) | ((amp[DAP1] + amp[DAP2]) < 5.0)), TAMANO] \\\n",
    "        = u'B'\n",
    "\n",
    "if len(amp[(amp[TAMANO] != u'L') & (((amp[DAPA] < 10) & (amp[DAPA] >= 2.5)) | (((amp[DAP1] + \n",
    "        amp[DAP2]) < 20) & ((amp[DAP1] + amp[DAP2]) >= 5.0)))]):\n",
    "    \n",
    "    logbuffer += u\"\\nLatizales están asignados a categoria erronea:\\n\"\n",
    "\n",
    "    logbuffer += amp[[PLOT, SPF, TAMANO, DAPA, DAP1, DAP2]][(amp[TAMANO] != 'L') & \n",
    "                    (((amp[DAPA] < 10) & (amp[DAPA] >= 2.5)) | (((amp[DAP1] + amp[DAP2]) < 20) \n",
    "                    & ((amp[DAP1] + amp[DAP2]) >= 5.0)))].join(info[[u'PLOT', u'SOCIO']].set_index(\n",
    "                    PLOT), on=PLOT, rsuffix=u'_info').to_string(index=False) + u\"\\n\"\n",
    "\n",
    "    amp.loc[(amp[TAMANO] != 'L') & (((amp[DAPA] < 10) & (amp[DAPA] >= 2.5)) | (((amp[DAP1] + \n",
    "        amp[DAP2]) < 20) & ((amp[DAP1] + amp[DAP2]) >= 5.0))), TAMANO] = u'L'\n",
    "    \n",
    "if len(amp[(amp[TAMANO] != u'F') & (((amp[DAPA] < 30) & (amp[DAPA] >= 10)) | (((amp[DAP1] + \n",
    "        amp[DAP2]) < 60) & ((amp[DAP1] + amp[DAP2]) >= 20)))]):\n",
    "    \n",
    "    logbuffer += u\"\\nFustales están asignados a categoria erronea:\\n\"\n",
    "    \n",
    "    logbuffer += amp[[PLOT, SPF, TAMANO, DAPA, DAP1, DAP2]][(amp[TAMANO] != 'F') & (((amp[DAPA] \n",
    "                    < 30) & (amp[DAPA] >= 10)) | (((amp[DAP1] + amp[DAP2]) < 60) & ((amp[DAP1] + \n",
    "                    amp[DAP2]) >= 20)))].join(info[[u'PLOT', u'SOCIO']].set_index(PLOT), on=PLOT, \n",
    "                    rsuffix=u'_info').to_string(index=False) + u\"\\n\"\n",
    "    \n",
    "    amp.loc[(amp[TAMANO] != u'F') & (((amp[DAPA] < 30) & (amp[DAPA] >= 10)) | (((amp[DAP1] + \n",
    "            amp[DAP2]) < 60) & ((amp[DAP1] + amp[DAP2]) >= 20))), TAMANO] = u'F'\n",
    "    \n",
    "if len(amp[(amp[TAMANO] != u'FG') & ((amp[DAPA] >= 30) | ((amp[DAP1] + amp[DAP2]) >= 60))]):\n",
    "    \n",
    "    logbuffer += u\"\\nFustales grandes están asignados a categoria erronea:\\n\"\n",
    "    \n",
    "    logbuffer += amp[[PLOT, SPF, TAMANO, DAPA, DAP1, DAP2]][(amp[TAMANO] != 'FG') & ((amp[DAPA]\n",
    "                    >= 30) | ((amp[DAP1] + amp[DAP2]) >= 60))].join(info[['PLOT', 'SOCIO']\n",
    "                    ].set_index(PLOT), on=PLOT, rsuffix='_info').to_string(index=False) + u\"\\n\"\n",
    "    \n",
    "    amp.loc[(amp[TAMANO] != u'FG') & ((amp[DAPA] >= 30) | ((amp[DAP1] + amp[DAP2]) >= 60)),\n",
    "        TAMANO] = u'FG'\n",
    "\n",
    "# Verificar si las distancias corresponden a las categorias de edad. Registros afuera \n",
    "# de sus respectivas areas son eliminados\n",
    "if len(amp[(amp[DIST] > 3) & (amp[TAMANO] == u'L')]):\n",
    "    \n",
    "    logbuffer += u\"\\nLatizales registrados afuera del area aceptada:\\n\"\n",
    "    \n",
    "    logbuffer += amp[[TAMANO, DIST, DAPA, PLOT, SPF]][(amp[DIST] > 3) & (amp[TAMANO] == u'L')\n",
    "                    ].join(info[[u'PLOT', u'SOCIO']].set_index(PLOT), on=PLOT, rsuffix=u'_info'\n",
    "                    ).to_string(index=False) + u\"\\n\"\n",
    "    \n",
    "    amp.drop(amp[(amp[DIST] > 3) & (amp[TAMANO] == u'L')].index, inplace=True)\n",
    "    \n",
    "if len(amp[(amp[DIST] > 7) & (amp[TAMANO] == u'F')]):\n",
    "    \n",
    "    logbuffer += u\"\\nFustales registrados afuera del area aceptada:\\n\"\n",
    "    \n",
    "    logbuffer += amp[[TAMANO, DIST, DAPA, PLOT, SPF]][(amp[DIST] > 7) & (amp[TAMANO] == u'F')\n",
    "                    ].join(info[[u'PLOT', u'SOCIO']].set_index(PLOT), on=PLOT, rsuffix=u'_info'\n",
    "                    ).to_string(index=False) + u\"\\n\"\n",
    "    \n",
    "    amp.drop(amp[(amp[DIST] > 7) & (amp[TAMANO] == u'F')].index, inplace=True)\n",
    "    \n",
    "if len(amp[amp[DIST] > 15]):\n",
    "    \n",
    "    logbuffer += u\"\\nIndividuos registrados afuera del area de la subparcela:\\n\"\n",
    "    \n",
    "    logbuffer += amp[[TAMANO, DIST, DAPA, PLOT, SPF]][amp[DIST] > 15].join(info[[u'PLOT', \n",
    "                    u'SOCIO']].set_index(PLOT), on=PLOT, rsuffix=u'_info').to_string(index=\n",
    "                    False) + u\"\\n\"\n",
    "\n",
    "    amp.drop(amp[amp[DIST] > 15].index, inplace = True)\n",
    "    \n",
    "# Altura total siempre debe ser mayor o igual a la altura del fuste\n",
    "# Si la altura de fuste es mayor entonces es reemplazada con la altura total\n",
    "if amp[amp[ALTF] > amp[ALTT]].size:\n",
    "    \n",
    "    logbuffer += u\"\\nIndividuos con altura del fuste mayor a la altura total:\\n\"\n",
    "    \n",
    "    logbuffer += amp[[ALTF, ALTT, PLOT, SPF]][amp[ALTF] > amp[ALTT]].join(info[[u'PLOT', \n",
    "                    u'SOCIO']].set_index(PLOT), on=PLOT, rsuffix=u'_info').to_string(index=\n",
    "                    False) + u\"\\n\"\n",
    "    \n",
    "    amp.loc[amp[ALTF] > amp[ALTT] , ALTF] = amp[amp[ALTF] > amp[ALTT]][ALTT]\n",
    "    \n",
    "# Punto de observacion de diametro\n",
    "if len(amp[(amp[POM] > amp[ALTT]) | (amp[POM] > 10.0)]):\n",
    "    \n",
    "    logbuffer += u\"\\nValores de Punto de observacion de la medida mayores a la altura o \" \\\n",
    "                    + u\"mayores a 10 m.\\n\"\n",
    "    \n",
    "    logbuffer += amp[[ALTT, ALTF, POM, FORMA_FUSTE, PLOT, SPF]][(amp[POM] > amp[ALTT]) | \n",
    "                    (amp[POM] > 10.0)].merge(info[[PLOT, SOCIO]], on=PLOT, how='left'\n",
    "                    ).to_string(index=False) + u\"\\n\"\n",
    "\n",
    "    # Se asume que todos los valores mayores a 10 m o a la altura total fueron erroneamente\n",
    "    # multiplicados por 10. Queda pendiente decidir que hacer con los valores mayores a 2 m\n",
    "    # de tallo cilindrico\n",
    "    amp.loc[((amp[POM] > amp[ALTT]) | (amp[POM] > 10.0)), POM] = amp[POM][(amp[POM] > \n",
    "        amp[ALTT])] / 10.0\n",
    "    \n",
    "# Informacion Penetrometro\n",
    "if amp[PI_cm].min() < 0:\n",
    "    \n",
    "    logbuffer += u\"\\nHay valores negativos de entrada del penetrometro.\\n\"\n",
    "    \n",
    "if amp[PI_cm].max() > 20:\n",
    "    \n",
    "    logbuffer += u\"\\nValores maximos del entrada del penetrometro mayores al valor sugerido\" \\\n",
    "                    +  u\"en el manual:\\n\"\n",
    "\n",
    "    logbuffer += amp[[PI_cm, PLOT, SPF]][amp[PI_cm] > 20].join(info[['PLOT', 'SOCIO']].set_index(\n",
    "            PLOT), on=PLOT, rsuffix='_info').to_string(index=False) + u\"\\n\"\n",
    "    \n",
    "    # Valores mayores a 20 cm son reestablecidos a 20 cm\n",
    "    amp.loc[amp[PI_cm] > 20 , PI_cm] = 20\n",
    "\n",
    "if len(amp[PI_cm][(amp[PI_cm] > amp[DAP1]) | (amp[PI_cm] > amp[DAP2])]):\n",
    "    \n",
    "    logbuffer += u\"\\nValores de entrada del penetrómetro son mayores al diametro registrado:\\n\"\n",
    "    \n",
    "    logbuffer += amp[[PI_cm, DAP1, DAP2, PLOT, SPF]][(amp[PI_cm] > amp[DAP1]) | (amp[PI_cm] \n",
    "                    > amp[DAP2])].join(info[[u'PLOT', u'SOCIO']].set_index(PLOT), on=PLOT, \n",
    "                    rsuffix=u'_info').to_string(index=False) + u\"\\n\"\n",
    "    \n",
    "    # Se asume que la medida del penetrometro equivale al diametro\n",
    "    amp.loc[(amp[PI_cm] > amp[DAP1]), PI_cm] = amp[DAP1][(amp[PI_cm] > amp[DAP1])]\n",
    "\n",
    "if amp[PI_golpes].min() < 0:\n",
    "    \n",
    "    logbuffer += u\"\\nValores negativos de golpes al penetrometro.\\n\"\n",
    "    \n",
    "if amp[PI_golpes].max() > 25:\n",
    "    \n",
    "    logbuffer += u\"\\nValores maximos de golpes del penetrometro son dudosos:\\n\"\n",
    "    \n",
    "    logbuffer += amp[[PI_golpes, PLOT, SPF]][amp[PI_golpes] > 20].join(info[[u'PLOT', u'SOCIO']\n",
    "                    ].set_index(PLOT), on=PLOT, rsuffix=u'_info').to_string(index=False) + u\"\\n\"\n",
    "\n",
    "# Depurar valores de forma de fuste a las abbreviaturas aceptadas\n",
    "amp[FORMA_FUSTE].replace(to_replace=[r'\\s+', u''], value=[u'', np.nan], regex=True, \n",
    "    inplace = True)\n",
    "\n",
    "amp[FORMA_FUSTE] = amp[FORMA_FUSTE].str.upper()\n",
    "\n",
    "# Los sigueintes son cambios basados en la presupocion de errores en el momento de ingresar datos\n",
    "# en el formato de toma de datos. \n",
    "\n",
    "amp.loc[((amp[FORMA_FUSTE] == u'HI') | (amp[FORMA_FUSTE] == u'Q')) , FORMA_FUSTE] = np.nan\n",
    "amp.loc[((amp[DANO] == u'IRR') & amp[FORMA_FUSTE].isna()) , FORMA_FUSTE] = u'IRR'\n",
    "amp.loc[((amp[DANO] == u'IRR') & (amp[FORMA_FUSTE] == u'IRR')) , DANO] = np.nan\n",
    "\n",
    "\n",
    "if interactive:\n",
    "    print logbuffer \n",
    "else:\n",
    "    with cd.open(logfile, mode='a', encoding='utf-8') as fhandle:\n",
    "        fhandle.write(logbuffer)\n",
    "logbuffer = u\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONS = u'CONS' # Indice coordenada (int64)\n",
    "PLOT = u'PLOT' # Indice conglomerado (int64)\n",
    "SPF = u'SPF' # Indice subparcela dentro del conglomerado (int64 1-5)\n",
    "SUBPLOT = u'SUBPLOT' # Concatenacion PLOT \"_\" SPF (str)\n",
    "LATITUD = u'LATITUD' # Latitud en formato decimal (float64)\n",
    "LONGITUD = u'LONGITUD' # Longitud en formato decimal (float64)\n",
    "REGION = u'REGION' # Region biogeografica (str: 'Amazonia', 'Andes', 'Pacifico', 'Orinoquia',\n",
    "                  # 'Caribe')\n",
    "ZV = u'ZV' # Zona de vida???????? (int64, 3, 4, 5, 6, 7, 13, 14, 15, 19, 20, 21, 27)\n",
    "ZONA_VIDA = u'ZONA_VIDA' # Zona de vida (str: \"Bosque húmedo tropical\",  \n",
    "    # \"Bosque muy húmedo tropical\",  \"Bosque húmedo montano bajo\",  \"Bosque pluvial premontano\",  \n",
    "    # \"Bosque muy húmedo premontano\",  \"Bosque húmedo premontano\",  \"Bosque muy húmedo montano\",  \n",
    "    # \"Bosque seco tropical\",  \"Bosque muy húmedo montano bajo\",  \"Bosque seco montano bajo\",  \n",
    "    # \"Bosque muy seco tropical\",  \"Monte espinoso subtropical\")\n",
    "EQ = u'EQ' # Ecuacion alometrica???? (int64: 1, 2, 4, 5, 6)\n",
    "E_CHAVE = u'E_CHAVE' # Coeficiente de la ecuacion de Chave (float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logbuffer = u\"\\n\" + u\"#\" * 50 + u\"\\nTABLA COORDENADAS\\n\"\n",
    "\n",
    "for fi in [CONS, PLOT, SPF, ZV, EQ]:\n",
    "    \n",
    "    if coord[fi].dtype != np.int64:\n",
    "        \n",
    "        logbuffer += u\"\\nCampo {0} tiene tipo inapropiado ({1} en vez de int64).\\n\".format(\n",
    "                        fi, coord[fi].dtype)\n",
    "        \n",
    "        if len(coord[fi][coord[fi].isna()]) > 1:\n",
    "            \n",
    "            logbuffer += u\"\\nLos siguentes valores nulos son considerados np.float64 por Pandas:\\n\"\n",
    "            \n",
    "            logbuffer += coord[[fi, PLOT, SPF]][amp[fi].isna()].merge(info[[PLOT, SOCIO]], \n",
    "                            on=PLOT, how='left').to_string(index=False) + u\"\\n\"\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            logbuffer += u\"\\nValores np.float64 a revisar:\\n\"\n",
    "            \n",
    "            logbuffer += coord[[fi, PLOT, SPF]][coord[fi].map(lambda x: x % 1.0 != 0)].dropna(\n",
    "                            ).merge(info[[PLOT, SOCIO]], on=PLOT, how='left').to_string(index=\n",
    "                            False) + u\"\\n\"\n",
    "            \n",
    "            \n",
    "for fi in [LATITUD, LONGITUD, E_CHAVE]:\n",
    "    \n",
    "    if coord[fi].dtype != np.float64:\n",
    "        \n",
    "        logbuffer += u\"\\nCampo {0} tiene tipo inapropiado ({1} en vez de float64)\\n.\".format(\n",
    "                        fi, coord[fi].dtype)\n",
    "        \n",
    "        \n",
    "for fi in [REGION, ZONA_VIDA]:\n",
    "    \n",
    "    non_strings = coord[fi].dropna()[~coord[fi].dropna().apply(type).eq(unicode)]\n",
    "    \n",
    "    if len(non_strings):\n",
    "        \n",
    "        logbuffer += u\"\\nCampo {0} tiene tipo inapropiado ({1} en vez de unicode).\\n\".format(\n",
    "                        fi, non_strings.dtype)\n",
    "\n",
    "if interactive:\n",
    "    print logbuffer\n",
    "    logbuffer = u\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Verificar que los indices no están duplicados\n",
    "if len(coord[coord[CONS].duplicated()]):\n",
    "    logbuffer += u\"\\nTabla {0} contiene indices duplicados\\n.\".format(coordenadas)\n",
    "\n",
    "# Verificar rangos de coordenadas \n",
    "lat_range = (-5, 15)\n",
    "lon_range = (-80, -65)\n",
    "\n",
    "if coord[LATITUD].min() < lat_range[0] or coord[LATITUD].max() > lat_range[1]:\n",
    "    \n",
    "    logbuffer +=  \"\\nLatitud fuerra de rango aceptado.\\n\"\n",
    "    \n",
    "if coord[LONGITUD].min() < lon_range[0] or coord[LONGITUD].max() > lon_range[1]:\n",
    "    \n",
    "    logbuffer +=  \"\\nLongitud fuerra de rango aceptado\\n\"\n",
    "\n",
    "# Verificar region geografica    \n",
    "for re in coord[REGION].unique():\n",
    "    \n",
    "    if re not in [u'Amazonia', u'Andes', u'Pacifico', u'Orinoquia', u'Caribe']:\n",
    "        \n",
    "        logbuffer += u\"\\nRegion biogeografica no aceptada: {0}\\n\".format(re)\n",
    "\n",
    "# Verificar que todas las parcelas están georeferenciadas\n",
    "integ = info[[PLOT,SPFC]].merge(coord[[PLOT, SPF, LATITUD, LONGITUD]], on=[PLOT], \n",
    "            how='left')\n",
    "\n",
    "if len(integ[integ[LATITUD].isna() | integ[LONGITUD].isna()]):\n",
    "    \n",
    "    logbuffer +=  \"\\nAlgunas parcelas no tienen coordenadas geograficas:\\n\"\n",
    "    \n",
    "    logbuffer += integ[integ[LATITUD].isna() | integ[LONGITUD].isna()].to_string(index=\n",
    "                    False) + u\"\\n\"\n",
    "    \n",
    "if interactive:\n",
    "    print logbuffer \n",
    "else:\n",
    "    with open(logfile, 'a') as fhandle:\n",
    "        fhandle.write(logbuffer)\n",
    "logbuffer = u\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inclusion de información en la base de datos\n",
    "Se incluyen los datos depurados en la base de datos MySQL a través del módulo SQLAlchemy. El esquema de la base de datos debe ser incluido con anterioridad al servidor local. Una copia del esquema está disponible en el archivo `Esquema_Inventario.sql`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlalchemy as al\n",
    "\n",
    "engine = al.create_engine(\n",
    "    'mysql+mysqldb://{0}:{1}@localhost/IFN?charset=utf8&use_unicode=1'.format(user, password),\n",
    "    encoding='utf-8')\n",
    "\n",
    "con = engine.connect()\n",
    "# Desactivar la verificación de foreign keys para la inserción en lote\n",
    "con.execute('SET foreign_key_checks = 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tabla Analizador\n",
    "\n",
    "analiz.rename(columns = {CONS: u\"AnalisisID\", PLOT: u\"Plot\", SPF: u\"Subparcela\", N: u\"Nitrogeno\",\n",
    "    C: u\"Carbono\"}).to_sql(\"Analizador\", con, if_exists = \"append\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tabla Carbono\n",
    "\n",
    "carb.rename(columns = {CONS: u\"CarbonoID\", PLOT: u\"Plot\", SPF: u\"Subparcela\", C: u\"Contenido\",\n",
    "    SUELO: u\"Masa\", RAIZ: u\"Raiz\", ROCA: u\"Roca\", VOL: u\"Volumen\", DENS: u\"Densidad\"}).to_sql(\n",
    "    \"Carbono\", con, if_exists = \"append\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tabla Fertilidad\n",
    "\n",
    "fert.rename(columns = {CONS: u\"FertID\", PLOT: u\"Plot\", TEXTURA: u\"Textura\", MO: u\"MateriaOrganica\",\n",
    "    A: u\"Arena\", L: u\"Limo\", Ar: u\"Arcilla\", pH: u\"pH\", CICE: u\"CICE\", Al: u\"Aluminio\", Ca: u\"Calcio\",\n",
    "    Cu: u\"Cobre\", P: u\"Fosforo\", Fe: u\"Hierro\", Mg: u\"Magnesio\", Mn: u\"Manganeso\", N: u\"Nitrogeno\",\n",
    "    K: u\"Potasio\", Zn: u\"Zinc\"}).to_sql(\"Fertilidad\", con, if_exists = \"append\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tabla Coordenadas\n",
    "\n",
    "coord[[PLOT, SPF, LATITUD, LONGITUD, ZV, ZONA_VIDA, EQ, E_CHAVE]].rename(columns = {PLOT: u'Plot', \n",
    "    SPF: u'SPF', LATITUD: u'Latitud', LONGITUD: u'Longitud', ZV: u'ZV', ZONA_VIDA: u'ZonaVida', \n",
    "    EQ: u'Eq', E_CHAVE: u'ChaveE'}).to_sql('Coordenadas', con, if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tabla Conglomerados\n",
    "\n",
    "info[[PLOT, DEPARTAMENTO, REGION, FECHA_CAMPO, SOCIO, SPFC]].rename(columns = {PLOT: u'PlotID',\n",
    "    DEPARTAMENTO: u'Departamento', REGION: u'Region', FECHA_CAMPO: u'Fecha', SOCIO: u'Socio', \n",
    "    SPFC: u'SFPC'}).to_sql('Conglomerados', con, if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tabla Taxonomia\n",
    "\n",
    "tax = {}\n",
    "\n",
    "for row in veg[[FAMILIA, GENERO, EPITETO, AUTOR]].itertuples():\n",
    "    tax[(row[1], row[2], row[3])] = row[4]\n",
    "    \n",
    "taxtemp = {FAMILIA:[], GENERO:[], EPITETO:[], AUTOR:[]}\n",
    "\n",
    "for (fam, gen, epi) in tax:\n",
    "    taxtemp[FAMILIA].append(fam)\n",
    "    taxtemp[GENERO].append(gen)\n",
    "    taxtemp[EPITETO].append(epi)\n",
    "    taxtemp[AUTOR].append(tax[(fam, gen, epi)])\n",
    "\n",
    "tax = None\n",
    "taxdf = pd.DataFrame.from_dict(taxtemp)\n",
    "taxtemp = None\n",
    "\n",
    "if taxdf.index[0] == 0:\n",
    "    taxdf.index += 1\n",
    "    \n",
    "taxdf[u'Fuente'] = 1\n",
    "\n",
    "taxdf.rename(columns = {FAMILIA: u'Familia', GENERO: u'Genero', AUTOR: u'Autor', EPITETO: u'Epiteto'}\n",
    "    ).to_sql('Taxonomia', con, if_exists='append', index_label=u'TaxonID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tabla Determinaciones\n",
    "\n",
    "if u'Taxon' not in taxdf.columns:\n",
    "    taxdf[u'Taxon'] = taxdf.index\n",
    "\n",
    "if 'Taxon' not in veg:\n",
    "    veg = veg.merge(taxdf[[FAMILIA, GENERO, EPITETO, u'Taxon']], on=[FAMILIA, GENERO, EPITETO],\n",
    "            how='left', suffixes = [u'_l', u'_r'])\n",
    "\n",
    "deters = veg.groupby(by=[PLOT, IND, u'Taxon']).size().reset_index().drop(axis=1, labels=0)\n",
    "\n",
    "if deters.index[0] == 0:\n",
    "    deters.index += 1\n",
    "\n",
    "deters[u'DetID'] = deters.index\n",
    "deters[[u'Taxon', u'DetID']].to_sql('Determinaciones', con, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tabla individuos\n",
    "\n",
    "if u'DetID' not in veg.columns:\n",
    "    veg = veg.merge(deters[[PLOT, IND, u'DetID']], on=[PLOT, IND], how='left')\n",
    "\n",
    "indAll = pd.concat([veg[[PLOT, IND]], amp[[PLOT, IND]]]).sort_values([PLOT,IND]).reset_index(\n",
    "    ).drop(axis=1, labels='index')\n",
    "indAll = indAll[~indAll.duplicated()]\n",
    "if indAll.index[0] == 0:\n",
    "    indAll.index += 1\n",
    "indAll['IndividuoID'] = indAll.index\n",
    "\n",
    "# Remover individuos con tallos multiples vivos Y muertos de la tabla arboles muerto en pie (amp)\n",
    "zombies = veg.merge(amp, on=[PLOT,IND], how = 'inner')[[PLOT, IND]]\n",
    "iz = zombies.set_index([PLOT,IND]).index\n",
    "ia = amp.set_index([PLOT,IND]).index\n",
    "amp_no_dups = amp.drop(amp[ia.isin(iz)].index)\n",
    "\n",
    "indpart = pd.concat([veg[[SPF, AZIMUT, DIST, PLOT, IND, u'DetID']], amp_no_dups[[SPF, AZIMUT, DIST, \n",
    "                PLOT, IND]]])\n",
    "\n",
    "indAll = indAll.merge(indpart, on=[PLOT, IND], how='inner').drop_duplicates(subset=u'IndividuoID')\n",
    "\n",
    "indAll[[PLOT, AZIMUT, SPF, DIST, u'DetID']].rename(columns = {PLOT: u'Plot', SPF: u'Subparcela', \n",
    "    AZIMUT: u'Azimut', DIST: u'Distancia', u'DetID': u'Dets'}).to_sql('Individuos', con, \n",
    "    if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tabla Tallos\n",
    "\n",
    "tallosparc = pd.concat([veg, amp])\n",
    "tallos = tallosparc.merge(indAll, on=[PLOT, IND], how='inner')\n",
    "tallos[[CONS, DAP1, DAP2, DAPA, DAP_EQUIPO, TAMANO, FORMA_FUSTE, ALTF, ALTT, ALT_EQUIPO, \n",
    "    u'IndividuoID', COND, POM, DANO, PI_cm, PI_golpes]].rename(columns = {CONS: u'TalloID', \n",
    "    DAP1: u'Diametro1', DAP2: u'Diametro2', DAPA: u'DiametroP', DAP_EQUIPO: u'EquipoDiam', \n",
    "    TAMANO: u'Tamano', FORMA_FUSTE: u'FormaFuste', ALTF: u'AlturaFuste', ALTT: u'AlturaTotal', \n",
    "    ALT_EQUIPO: u'EquipoAlt', u'IndividuoID': u'Individuo', COND: u'Condicion', POM: u'POM', \n",
    "    DANO: u'Dano', PI_cm: u'PetrProf', PI_golpes: u'PetrGolpes'}).to_sql(u'Tallos', con, \n",
    "    if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tabla Detritos\n",
    "PI_cm, PI_golpes = u'PI_cm', u'PI_golpes'\n",
    "\n",
    "det[[CONS, PLOT, TRAN, SECC, PIEZA, TIPO, DIST, AZIMUT, D1, D2, INCL, PI_cm, PI_golpes, \n",
    "    PESO_RODAJA, PESO_MUESTRA, PESO_SECO, ESP1, ESP2, ESP3, ESP4, VOL, DENS]].rename(\n",
    "    columns = {CONS: u'DETRITOID', PLOT: u'PLOT', TRAN: u'Transecto', SECC: u'Seccion', \n",
    "    PIEZA: u'Pieza', TIPO: u'Tipo', DIST: u'Distancia', AZIMUT: u'Azimut', D1: u'Diametro1', \n",
    "    D2: u'Diametro2', INCL: u'Inclinacion', PI_cm: u'PetrProf', PI_golpes: u'PetrGolpes',\n",
    "    PESO_RODAJA: u'PesoRodaja', PESO_MUESTRA: u'PesoMuestra', PESO_SECO: u'PesoSeco', \n",
    "    ESP1: u'Espesor1', ESP2: u'Espesor2', ESP3: u'Espesor3', ESP4: u'Espesor4', \n",
    "    VOL: u'Volumen', DENS: u'Densidad'}).to_sql(u'Detritos', con, \n",
    "    if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Restituir la verificación de foreign keys\n",
    "con.execute('SET foreign_key_checks = 1')\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
