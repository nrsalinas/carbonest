{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biomass spatial progation through GBT\n",
    "\n",
    "Local biomass estimates are spatially propagated through Gradient Boosted Trees regression.\n",
    "Input features are a set of environmental variables: elevation, precipitation, etc. Data from these features is usually loaded from raster files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gdal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Raster data should be downsampled if it is too big to be loaded in memory\n",
    "def rebin(arr, new_shape):\n",
    "    \"\"\"Downsampling array.\"\"\"\n",
    "    shape = (new_shape[0], arr.shape[0] / new_shape[0],\n",
    "             new_shape[1], arr.shape[1] / new_shape[1])\n",
    "    return arr.reshape(shape).mean(-1).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nelsonsalinas/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:35: RuntimeWarning: invalid value encountered in greater\n",
      "/home/nelsonsalinas/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:49: RuntimeWarning: invalid value encountered in greater\n",
      "/home/nelsonsalinas/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:62: RuntimeWarning: invalid value encountered in greater\n",
      "/home/nelsonsalinas/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in greater\n"
     ]
    }
   ],
   "source": [
    "factor = 1 # downsampling factor to acquire array data from bands\n",
    "\n",
    "# Paths to raster files of environmental data\n",
    "alt_file = \"/home/nelsonsalinas/Documents/cust_layers/alt/alt.tif\"\n",
    "\n",
    "prec_folder = \"/home/nelsonsalinas/Documents/cust_layers/precp\"\n",
    "suff = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "prec_files = [\"{0}/vent_prec_{1}.tif\".format(prec_folder, x) for x in suff]\n",
    "\n",
    "ave_temp_folder = \"/home/nelsonsalinas/Documents/cust_layers/ave_temp/\"\n",
    "suff = map(str, range(1,13))\n",
    "ave_temp_files = [\"{0}/{1}.tif\".format(ave_temp_folder, x) for x in suff]\n",
    "\n",
    "bio_var_folder = \"/home/nelsonsalinas/Documents/cust_layers/biovars\"\n",
    "suff = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '14', '15', '16', '17', '18', '19']\n",
    "bio_var_files = [\"{0}/biovar_{1}.tif\".format(bio_var_folder, x) for x in suff]\n",
    "\n",
    "alt_ras = gdal.Open(alt_file)\n",
    "#prec_ras = [gdal.Open(x) for x in prec_files]\n",
    "#bio_var_ras = [gdal.Open(x) for x in bio_var_files]\n",
    "\n",
    "# Matedata from rasters\n",
    "transform = alt_ras.GetGeoTransform()\n",
    "altXOrigin = transform[0]\n",
    "altYOrigin = transform[3]\n",
    "altPixelWidth = transform[1]\n",
    "altPixelHeight = transform[5]\n",
    "\n",
    "# Load raster data as numpy.array objects\n",
    "alt_band = alt_ras.GetRasterBand(1)\n",
    "alt_arr = alt_band.ReadAsArray(0, 0, alt_ras.RasterXSize, alt_ras.RasterYSize)\n",
    "# Replace unknown values with NANs\n",
    "np.place(alt_arr, ~np.isfinite(alt_arr), np.nan)\n",
    "np.place(alt_arr, alt_arr < -30, np.nan)\n",
    "np.place(alt_arr, alt_arr > 6000, np.nan)\n",
    "#alt_arr = rebin(alt_arr, (alt_arr.shape[0] / factor, alt_arr.shape[1] / factor))\n",
    "\n",
    "prec_arrs = []\n",
    "for prfi in prec_files:\n",
    "    prec_ras = gdal.Open(prfi)\n",
    "    prec_band = prec_ras.GetRasterBand(1)\n",
    "    prec_i = prec_band.ReadAsArray(0, 0, prec_ras.RasterXSize, prec_ras.RasterYSize)\n",
    "    prec_i = prec_i.astype(float)\n",
    "    #prec_arrs.append(prec_band.ReadAsArray(0, 0, prec_ras.RasterXSize, prec_ras.RasterYSize))\n",
    "    \n",
    "    # Replace unknown values with NANs\n",
    "    np.place(prec_i, ~np.isfinite(prec_i), np.nan)\n",
    "    np.place(prec_i, prec_i < 0, np.nan)\n",
    "    np.place(prec_i, prec_i > 2000, np.nan)\n",
    "    #prec_i = rebin(prec_i, (prec_i.shape[0] / factor, prec_i.shape[1] / factor))\n",
    "    prec_arrs.append(prec_i)\n",
    "\n",
    "bio_var_arrs = []\n",
    "for biofi in bio_var_files:\n",
    "    bio_var_ras = gdal.Open(biofi) \n",
    "    bio_var_band = bio_var_ras.GetRasterBand(1)\n",
    "    bio_i = bio_var_band.ReadAsArray(0, 0, bio_var_ras.RasterXSize, bio_var_ras.RasterYSize)\n",
    "    bio_i = bio_i.astype(float)\n",
    "    # Replace unknown values with NANs\n",
    "    np.place(bio_i, ~np.isfinite(bio_i), np.nan)\n",
    "    np.place(bio_i, bio_i < -20, np.nan)\n",
    "    np.place(bio_i, bio_i > 2000, np.nan)\n",
    "    #bio_i = rebin(bio_i, (bio_i.shape[0] / factor, bio_i.shape[1] / factor))\n",
    "    bio_var_arrs.append(bio_i)\n",
    "    \n",
    "ave_temp_arrs = []\n",
    "for avefi in ave_temp_files:\n",
    "    ave_temp_ras = gdal.Open(avefi) \n",
    "    ave_temp_band = ave_temp_ras.GetRasterBand(1)\n",
    "    ave_temp_i = ave_temp_band.ReadAsArray(0, 0, ave_temp_ras.RasterXSize, ave_temp_ras.RasterYSize)\n",
    "    ave_temp_i = ave_temp_i.astype(float)\n",
    "    # Replace unknown values with NANs\n",
    "    np.place(ave_temp_i, ~np.isfinite(ave_temp_i), np.nan)\n",
    "    np.place(ave_temp_i, ave_temp_i < -20, np.nan)\n",
    "    np.place(ave_temp_i, ave_temp_i > 60, np.nan)\n",
    "    #bio_i = rebin(bio_i, (bio_i.shape[0] / factor, bio_i.shape[1] / factor))\n",
    "    ave_temp_arrs.append(ave_temp_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load biomass estimations based on plot data \n",
    "biomass = pd.read_csv(\"biomass_all_20180118.csv\")\n",
    "\n",
    "biomass['X'] = biomass.Longitud.apply(lambda x: int((x - altXOrigin) / altPixelWidth))\n",
    "biomass['Y'] = biomass.Latitud.apply(lambda y: int((y - altYOrigin) / altPixelHeight))\n",
    "\n",
    "biopix = biomass.groupby(['X','Y']).size().reset_index().drop(columns=0)\n",
    "\n",
    "biopix['chaveII'] = np.nan\n",
    "for row in biopix.itertuples():\n",
    "    biopix.loc[(biopix.X == row.X) & (biopix.Y == row.Y), 'chaveII'] = \\\n",
    "        biomass[(biomass.X == row.X) & (biomass.Y == row.Y)]['chaveII'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select environmental data from pixels where biomass estimates have been conducted\n",
    "X = np.empty((biopix.shape[0], (len(ave_temp_arrs) + len(bio_var_arrs) + len(prec_arrs) + 1)))\n",
    "X[:,0] = alt_arr[biopix.Y, biopix.X]\n",
    "for inx,arr in enumerate(prec_arrs + ave_temp_arrs + bio_var_arrs):\n",
    "    ni = inx + 1\n",
    "    X[:,ni] = arr[biopix.Y, biopix.X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GBT estimator does not accept missing data, therefore cells with missing data will be filled with the variable mean \n",
    "imp = Imputer()\n",
    "imp = imp.fit(X)\n",
    "X = imp.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'n_estimators': [16, 17, 18, 19, 20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First find optimal number of trees for learning rate 0.1\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pars = {'n_estimators' : range(16,21)}\n",
    "gbtr = GradientBoostingRegressor(learning_rate=0.1)\n",
    "grid_search = GridSearchCV(estimator = gbtr, param_grid = pars, cv = 5, n_jobs=4, \\\n",
    "        scoring= 'neg_mean_squared_error')\n",
    "grid_search.fit(X, biopix.chaveII.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nelsonsalinas/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:747: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: -277824007028.16309, std: 220379906215.75491, params: {'n_estimators': 16},\n",
       "  mean: -274415894635.20029, std: 221539039479.13312, params: {'n_estimators': 17},\n",
       "  mean: -273854563683.24167, std: 222138837111.40463, params: {'n_estimators': 18},\n",
       "  mean: -275865116844.12152, std: 221488278272.43936, params: {'n_estimators': 19},\n",
       "  mean: -276466402902.92169, std: 222163601511.90448, params: {'n_estimators': 20}],\n",
       " {'n_estimators': 18},\n",
       " -273854563683.24167)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.grid_scores_, grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter space\n",
    "pars = {'min_samples_split' = 3,\n",
    "        'min_samples_leaf' = 3,\n",
    "        'max_depth' = [3, 7, 12],\n",
    "        'max_features' = [7, 12, 17],\n",
    "        'n_estimators' = [100, 200, 500],\n",
    "        'subsample' = [0.3, 0.5, 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomly split input and response data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, biopix.chaveII.as_matrix(), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the regression model\n",
    "gbtr = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.1)\n",
    "gbtr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Estimate the r regression coefficient\n",
    "r2_score(y_test, gbtr.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
