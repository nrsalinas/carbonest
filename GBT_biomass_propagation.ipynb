{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biomass spatial progation through GBT\n",
    "\n",
    "Local biomass estimates are spatially propagated through Gradient Boosted Trees regression.\n",
    "Input features are a set of environmental variables: elevation, precipitation, etc. Data from these features is usually loaded from raster files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gdal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Raster data should be downsampled if it is too big to be loaded in memory\n",
    "def rebin(arr, new_shape):\n",
    "    \"\"\"Downsampling array.\"\"\"\n",
    "    shape = (new_shape[0], arr.shape[0] / new_shape[0],\n",
    "             new_shape[1], arr.shape[1] / new_shape[1])\n",
    "    return arr.reshape(shape).mean(-1).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nelsonsalinas/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:35: RuntimeWarning: invalid value encountered in greater\n",
      "/home/nelsonsalinas/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:49: RuntimeWarning: invalid value encountered in greater\n",
      "/home/nelsonsalinas/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:62: RuntimeWarning: invalid value encountered in greater\n",
      "/home/nelsonsalinas/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in greater\n"
     ]
    }
   ],
   "source": [
    "factor = 1 # downsampling factor to acquire array data from bands\n",
    "\n",
    "# Paths to raster files of environmental data\n",
    "alt_file = \"/home/nelsonsalinas/Documents/cust_layers/alt/alt.tif\"\n",
    "\n",
    "prec_folder = \"/home/nelsonsalinas/Documents/cust_layers/precp\"\n",
    "suff = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "prec_files = [\"{0}/vent_prec_{1}.tif\".format(prec_folder, x) for x in suff]\n",
    "\n",
    "ave_temp_folder = \"/home/nelsonsalinas/Documents/cust_layers/ave_temp/\"\n",
    "suff = map(str, range(1,13))\n",
    "ave_temp_files = [\"{0}/{1}.tif\".format(ave_temp_folder, x) for x in suff]\n",
    "\n",
    "bio_var_folder = \"/home/nelsonsalinas/Documents/cust_layers/biovars\"\n",
    "suff = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '14', '15', '16', '17', '18', '19']\n",
    "bio_var_files = [\"{0}/biovar_{1}.tif\".format(bio_var_folder, x) for x in suff]\n",
    "\n",
    "alt_ras = gdal.Open(alt_file)\n",
    "#prec_ras = [gdal.Open(x) for x in prec_files]\n",
    "#bio_var_ras = [gdal.Open(x) for x in bio_var_files]\n",
    "\n",
    "# Matedata from rasters\n",
    "transform = alt_ras.GetGeoTransform()\n",
    "altXOrigin = transform[0]\n",
    "altYOrigin = transform[3]\n",
    "altPixelWidth = transform[1]\n",
    "altPixelHeight = transform[5]\n",
    "\n",
    "# Load raster data as numpy.array objects\n",
    "alt_band = alt_ras.GetRasterBand(1)\n",
    "alt_arr = alt_band.ReadAsArray(0, 0, alt_ras.RasterXSize, alt_ras.RasterYSize)\n",
    "# Replace unknown values with NANs\n",
    "np.place(alt_arr, ~np.isfinite(alt_arr), np.nan)\n",
    "np.place(alt_arr, alt_arr < -30, np.nan)\n",
    "np.place(alt_arr, alt_arr > 6000, np.nan)\n",
    "#alt_arr = rebin(alt_arr, (alt_arr.shape[0] / factor, alt_arr.shape[1] / factor))\n",
    "\n",
    "prec_arrs = []\n",
    "for prfi in prec_files:\n",
    "    prec_ras = gdal.Open(prfi)\n",
    "    prec_band = prec_ras.GetRasterBand(1)\n",
    "    prec_i = prec_band.ReadAsArray(0, 0, prec_ras.RasterXSize, prec_ras.RasterYSize)\n",
    "    prec_i = prec_i.astype(float)\n",
    "    #prec_arrs.append(prec_band.ReadAsArray(0, 0, prec_ras.RasterXSize, prec_ras.RasterYSize))\n",
    "    \n",
    "    # Replace unknown values with NANs\n",
    "    np.place(prec_i, ~np.isfinite(prec_i), np.nan)\n",
    "    np.place(prec_i, prec_i < 0, np.nan)\n",
    "    np.place(prec_i, prec_i > 2000, np.nan)\n",
    "    #prec_i = rebin(prec_i, (prec_i.shape[0] / factor, prec_i.shape[1] / factor))\n",
    "    prec_arrs.append(prec_i)\n",
    "\n",
    "bio_var_arrs = []\n",
    "for biofi in bio_var_files:\n",
    "    bio_var_ras = gdal.Open(biofi) \n",
    "    bio_var_band = bio_var_ras.GetRasterBand(1)\n",
    "    bio_i = bio_var_band.ReadAsArray(0, 0, bio_var_ras.RasterXSize, bio_var_ras.RasterYSize)\n",
    "    bio_i = bio_i.astype(float)\n",
    "    # Replace unknown values with NANs\n",
    "    np.place(bio_i, ~np.isfinite(bio_i), np.nan)\n",
    "    np.place(bio_i, bio_i < -20, np.nan)\n",
    "    np.place(bio_i, bio_i > 2000, np.nan)\n",
    "    #bio_i = rebin(bio_i, (bio_i.shape[0] / factor, bio_i.shape[1] / factor))\n",
    "    bio_var_arrs.append(bio_i)\n",
    "    \n",
    "ave_temp_arrs = []\n",
    "for avefi in ave_temp_files:\n",
    "    ave_temp_ras = gdal.Open(avefi) \n",
    "    ave_temp_band = ave_temp_ras.GetRasterBand(1)\n",
    "    ave_temp_i = ave_temp_band.ReadAsArray(0, 0, ave_temp_ras.RasterXSize, ave_temp_ras.RasterYSize)\n",
    "    ave_temp_i = ave_temp_i.astype(float)\n",
    "    # Replace unknown values with NANs\n",
    "    np.place(ave_temp_i, ~np.isfinite(ave_temp_i), np.nan)\n",
    "    np.place(ave_temp_i, ave_temp_i < -20, np.nan)\n",
    "    np.place(ave_temp_i, ave_temp_i > 60, np.nan)\n",
    "    #bio_i = rebin(bio_i, (bio_i.shape[0] / factor, bio_i.shape[1] / factor))\n",
    "    ave_temp_arrs.append(ave_temp_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load biomass estimations based on plot data \n",
    "biomass = pd.read_csv(\"biomass_all_20180118.csv\")\n",
    "\n",
    "biomass['X'] = biomass.Longitud.apply(lambda x: int((x - altXOrigin) / altPixelWidth))\n",
    "biomass['Y'] = biomass.Latitud.apply(lambda y: int((y - altYOrigin) / altPixelHeight))\n",
    "\n",
    "biopix = biomass.groupby(['X','Y']).size().reset_index().drop(columns=0)\n",
    "\n",
    "biopix['chaveII'] = np.nan\n",
    "for row in biopix.itertuples():\n",
    "    biopix.loc[(biopix.X == row.X) & (biopix.Y == row.Y), 'chaveII'] = \\\n",
    "        biomass[(biomass.X == row.X) & (biomass.Y == row.Y)]['chaveII'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select environmental data from pixels where biomass estimates have been conducted\n",
    "X = np.empty((biopix.shape[0], (len(ave_temp_arrs) + len(bio_var_arrs) + len(prec_arrs) + 1)))\n",
    "X[:,0] = alt_arr[biopix.Y, biopix.X]\n",
    "for inx,arr in enumerate(prec_arrs + ave_temp_arrs + bio_var_arrs):\n",
    "    ni = inx + 1\n",
    "    X[:,ni] = arr[biopix.Y, biopix.X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GBT estimator does not accept missing data, therefore cells with missing data will be filled with the variable mean \n",
    "imp = Imputer()\n",
    "imp = imp.fit(X)\n",
    "X = imp.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scaler = StandardScaler()\n",
    "my_scaler.fit(X)\n",
    "X_scaled = my_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=6,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=20, min_samples_split=22,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "             presort='auto', random_state=None, subsample=0.8, verbose=0,\n",
       "             warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'n_estimators': [1, 2, 3, 4, 5, 6, 7, 8, 9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First find optimal number of trees for learning rate 0.1\n",
    "\n",
    "\n",
    "pars = {'n_estimators' : range(1, 10)\n",
    "       }\n",
    "\n",
    "gbtr = GradientBoostingRegressor(learning_rate=0.1, min_samples_split=22, min_samples_leaf = 20,\n",
    "        max_depth = 6, max_features = \"sqrt\", subsample = 0.8)\n",
    "\n",
    "grid_search = GridSearchCV(estimator = gbtr, param_grid = pars, cv = 10, n_jobs=4, \\\n",
    "    scoring= 'neg_mean_absolute_error')\n",
    "\n",
    "grid_search.fit(X_scaled, biopix.chaveII.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nelsonsalinas/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:747: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: -205710.21510, std: 42174.99228, params: {'n_estimators': 1},\n",
       "  mean: -204075.72671, std: 40574.53088, params: {'n_estimators': 2},\n",
       "  mean: -207669.29407, std: 35702.03956, params: {'n_estimators': 3},\n",
       "  mean: -204548.79909, std: 39388.29956, params: {'n_estimators': 4},\n",
       "  mean: -202813.12523, std: 40668.18235, params: {'n_estimators': 5},\n",
       "  mean: -209679.31626, std: 37803.18897, params: {'n_estimators': 6},\n",
       "  mean: -213617.96557, std: 35461.57116, params: {'n_estimators': 7},\n",
       "  mean: -208242.02925, std: 37498.98554, params: {'n_estimators': 8},\n",
       "  mean: -212701.53426, std: 44582.67582, params: {'n_estimators': 9}],\n",
       " {'n_estimators': 5},\n",
       " -202813.12523094259)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.grid_scores_, grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter space\n",
    "pars = {'min_samples_split' = 3,\n",
    "        'min_samples_leaf' = 3,\n",
    "        'max_depth' = [3, 7, 12],\n",
    "        'max_features' = [7, 12, 17],\n",
    "        'n_estimators' = [100, 200, 500],\n",
    "        'subsample' = [0.3, 0.5, 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomly split input and response data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, biopix.chaveII.as_matrix(), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the regression model\n",
    "gbtr = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.1)\n",
    "gbtr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Estimate the r regression coefficient\n",
    "r2_score(y_test, gbtr.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
