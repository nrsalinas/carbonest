{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biomass spatial progation through GBT\n",
    "\n",
    "Local biomass estimates are spatially propagated through Gradient Boosted Trees regression.\n",
    "Input features are a set of environmental variables: elevation, precipitation, etc. Data from these features is usually loaded from raster files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gdal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Raster data should be downsampled if it is too big to be loaded in memory\n",
    "def rebin(arr, new_shape):\n",
    "    \"\"\"Downsampling array.\"\"\"\n",
    "    shape = (new_shape[0], arr.shape[0] / new_shape[0],\n",
    "             new_shape[1], arr.shape[1] / new_shape[1])\n",
    "    return arr.reshape(shape).mean(-1).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "factor = 1 # downsampling factor to acquire array data from bands\n",
    "\n",
    "# Paths to raster files of environmental data\n",
    "alt_file = \"/home/nelsonsalinas/Documents/cust_layers/alt/alt.tif\"\n",
    "\n",
    "prec_folder = \"/home/nelsonsalinas/Documents/cust_layers/precp\"\n",
    "suff = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "prec_files = [\"{0}/vent_prec_{1}.tif\".format(prec_folder, x) for x in suff]\n",
    "\n",
    "bio_var_folder = \"/home/nelsonsalinas/Documents/cust_layers/biovars\"\n",
    "suff = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '14', '15', '16', '17', '18', '19']\n",
    "bio_var_files = [\"{0}/biovar_{1}.tif\".format(bio_var_folder, x) for x in suff]\n",
    "\n",
    "alt_ras = gdal.Open(alt_file)\n",
    "#prec_ras = [gdal.Open(x) for x in prec_files]\n",
    "#bio_var_ras = [gdal.Open(x) for x in bio_var_files]\n",
    "\n",
    "# Matedata from rasters\n",
    "transform = alt_ras.GetGeoTransform()\n",
    "altXOrigin = transform[0]\n",
    "altYOrigin = transform[3]\n",
    "altPixelWidth = transform[1]\n",
    "altPixelHeight = transform[5]\n",
    "\n",
    "# Load raster data as numpy.array objects\n",
    "alt_band = alt_ras.GetRasterBand(1)\n",
    "alt_arr = alt_band.ReadAsArray(0, 0, alt_ras.RasterXSize, alt_ras.RasterYSize)\n",
    "np.place(alt_arr, alt_arr < 0, np.nan) # Replace unknown values with NANs\n",
    "alt_arr = rebin(alt_arr, (alt_arr.shape[0] / factor, alt_arr.shape[1] / factor))\n",
    "\n",
    "prec_arrs = []\n",
    "for prfi in prec_files:\n",
    "    prec_ras = gdal.Open(prfi)\n",
    "    prec_band = prec_ras.GetRasterBand(1)\n",
    "    prec_i = prec_band.ReadAsArray(0, 0, prec_ras.RasterXSize, prec_ras.RasterYSize)\n",
    "    prec_i = prec_i.astype(float)\n",
    "    #prec_arrs.append(prec_band.ReadAsArray(0, 0, prec_ras.RasterXSize, prec_ras.RasterYSize))\n",
    "    np.place(prec_i, prec_i < 0, np.nan) # Replace unknown values with NANs\n",
    "    prec_i = rebin(prec_i, (prec_i.shape[0] / factor, prec_i.shape[1] / factor))\n",
    "    prec_arrs.append(prec_i)\n",
    "\n",
    "bio_var_arrs = []\n",
    "for biofi in bio_var_files:\n",
    "    bio_var_ras = gdal.Open(biofi) \n",
    "    bio_var_band = bio_var_ras.GetRasterBand(1)\n",
    "    bio_i = bio_var_band.ReadAsArray(0, 0, bio_var_ras.RasterXSize, bio_var_ras.RasterYSize)\n",
    "    bio_i = bio_i.astype(float)\n",
    "    np.place(bio_i, bio_i < 0, np.nan) # Replace unknown values with NANs\n",
    "    bio_i = rebin(bio_i, (bio_i.shape[0] / factor, bio_i.shape[1] / factor))\n",
    "    bio_var_arrs.append(bio_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load biomass estimations based on plot data \n",
    "biomass = pd.read_csv(\"biomass_all_20180118.csv\")\n",
    "\n",
    "biomass['X'] = biomass.Longitud.apply(lambda x: int((x - altXOrigin) / altPixelWidth))\n",
    "biomass['Y'] = biomass.Latitud.apply(lambda y: int((y - altYOrigin) / altPixelHeight))\n",
    "\n",
    "biopix = biomass.groupby(['X','Y']).size().reset_index().drop(columns=0)\n",
    "\n",
    "biopix['chaveII'] = np.nan\n",
    "for row in biopix.itertuples():\n",
    "    biopix.loc[(biopix.X == row.X) & (biopix.Y == row.Y), 'chaveII'] = \\\n",
    "        biomass[(biomass.X == row.X) & (biomass.Y == row.Y)]['chaveII'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select environmental data from pixels where biomass estimates have been conducted\n",
    "X = np.empty((biopix.shape[0], (len(prec_arrs) + 1)))\n",
    "X[:,0] = alt_arr[biopix.Y, biopix.X]\n",
    "for inx,arr in enumerate(prec_arrs):\n",
    "    ni = inx + 1\n",
    "    X[:,ni] = arr[biopix.Y, biopix.X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GBT estimator does not accept missing data, therefore cells with missing data will be filled with the variable mean \n",
    "imp = Imputer()\n",
    "imp = imp.fit(X)\n",
    "X = imp.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomly split input and response data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, biopix.chaveII.as_matrix(), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the regression model\n",
    "gbtr = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.1)\n",
    "gbtr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Estimate the r regression coefficient\n",
    "r2_score(y_test, gbtr.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
