{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depuracion datos Inventario Forestal Nacional\n",
    "\n",
    "El presente notebook realiza la exploración inicial y depuración de datos del Inventario Forestal Nacional.\n",
    "\n",
    "**Módulos requeridos:** Numpy y Pandas para la depuración de datos, SQLAlchemy para la inserción de información en las bases de datos.\n",
    "\n",
    "Las siguientes variables indican la ubicación de las tablas de entrada en formato csv:\n",
    "\n",
    "1. `detritos`: Contiene los mediciones realizadas en detritos de madera.\n",
    "\n",
    "2. `ampie`: Mediciones de árboles muertos en pie.\n",
    "    \n",
    "3. `vegetacion`: Mediciones de árboles vivos.\n",
    "\n",
    "4. `generalInfo`: Informacion general de cada conglomerado\n",
    "\n",
    "5. `coordenadas`: Coordenadas de parcelas\n",
    "\n",
    "También es necesario indicar las credenciales de accesos al servidor MySQL a través de las variables `user` (nombre de usuario) y `password` (clave de acceso).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs as cd\n",
    "import re\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Si se quieren realizar visualizaciones en las celdas:\n",
    "# %matplotlib inline\n",
    "\n",
    "# Si el script es ejecutado interactivamente (como un cuaderno Jupyter, por ejemplo)\n",
    "# la variable `interactive` debe ser `True`, de lo contrario los reportes de error\n",
    "# serán guardados en un archivo de texto (`logfile`).\n",
    "interactive = False\n",
    "\n",
    "# Archivo con reportes de error\n",
    "logfile = u\"revisar_20180323.txt\"\n",
    "\n",
    "logbuffer = u\"\"\n",
    "\n",
    "# MySQL user and password\n",
    "password = u\"\"\n",
    "user = u\"\"\n",
    "\n",
    "# Asignar nombres de archivos a variables\n",
    "#detritos = u\"../data/IFN/detritos.csv\"\n",
    "#ampie =  u\"../../data_2018/amp_to_clean.csv\"\n",
    "#vegetacion = u\"../../data_2018/veg_to_clean.csv\"\n",
    "individuos = u\"../../data_2018/ifn_to_clean.csv\"\n",
    "#generalInfo = u\"../data/IFN/informacion_general/informacion_general.csv\"\n",
    "coordenadas = u\"../../data_2018/ifn_coordenadas.csv\"\n",
    "#analizador = u\"../data/IFN/suelos/analizador.csv\"\n",
    "#carbono = u\"../data/IFN/suelos/carbono.csv\"\n",
    "#fertilidad = u\"../data/IFN/suelos/fertilidad.csv\"\n",
    "\n",
    "# Leer archivos como Pandas dataframes\n",
    "#det = pd.read_csv(detritos, encoding = 'utf8') \n",
    "#amp = pd.read_csv(ampie, encoding = 'utf8')\n",
    "#veg = pd.read_csv(vegetacion, encoding = 'utf8')\n",
    "inds = pd.read_csv(individuos, encoding = 'utf8')\n",
    "#info = pd.read_csv(generalInfo, encoding = 'utf8')\n",
    "coord = pd.read_csv(coordenadas, encoding = 'utf8')\n",
    "#analiz = pd.read_csv(analizador, encoding = 'utf8')\n",
    "#carb = pd.read_csv(carbono, encoding = 'utf8')\n",
    "#fert = pd.read_csv(fertilidad, encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vegetacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PLOT = u\"CODIGO_CONGLOMERADO\" # Indice conglomerado (int)\n",
    "SPF = u\"CODIGO_SUBPARCELA\" # Indice subparcela (int 1-5)\n",
    "IND = u\"NUMERO_ID\" # Indice de individuo en el conglomerado (int)\n",
    "NFUSTE = u\"NUMERO_FUSTE\" # Indice del fuste\n",
    "TIPO1 = u'TIPO_FUSTE'\n",
    "TIPO2 = u'IND_O_FUSTE'\n",
    "TAMANO = u\"TIPO_INDIVIDUO\" # Tamaño del individuo (str: 'L', 'F', o 'FG')\n",
    "AZIMUT = u\"AZIMUT\" # Orientacion del individuo desde el centro de la subparcela (int, 0-360)\n",
    "DIST = u\"DISTANCIA\" # Distancia en m del individuo al centro de la parcela (float, 0-15.74)\n",
    "DAP1 = u\"DAP1\" # Primer diámetro estimado del tallo en cm (float)\n",
    "DAP2 = u\"DAP2\" # Segundo diámetro estimado del tallo en cm (float)\n",
    "DAPA = u\"Dapa\" # Diametro promedio del tallo en cm (float)\n",
    "ALTF = u\"ALTURA_FUSTE\" # Altura fuste en m (float)\n",
    "ALTT = u\"ALTURA_TOTAL\" # Altura total en m (float)\n",
    "FAMILIA = u\"FAMILIA_CALCULADO\" # Familia taxonomica (str)\n",
    "GENERO = u\"GENERO_CALCULADO\" # Genero taxonomico (str)\n",
    "EPITETO = u\"ESPECIE_CALCULADA\" # Epiteto taxonomico (str)\n",
    "PI_cm = u\"PENETRACION\" # Penetracion del penetrometro en cm (float64).\n",
    "PI_golpes = u\"NUMERO_PENETRACIONES\" # Golpes ejecutados con el penetrometro (float64). Por que es un numero\n",
    "POM = u'POM' # Punto de observacion de la medida en m (float64). Hay medidas en cm.\n",
    "ALT_EQUIPO = u'EQUIPO2' # Equipo usado en la medicion de la altura (str: 'HI', 'VT', 'CL', 'CM', 'VX', 'FL', 'CD'). Valores 'CM', 'VX', 'FL' y 'CD' no esta especificados en el manual del INF.???????????????????\n",
    "DAP_EQUIPO = u\"EQUIPO1\" # Equipo empleado en la medicion de DAP (str: 'CD', 'FO', 'CA', 'CM'). Cuales son CM y CD? No estan especificados en el manual del INF.\n",
    "FORMA_FUSTE = u'FORMA_FUSTE' # (str: 'CIL', 'RT','IRR','FA','HI','Q'). Clases de valores estan repetidos por insercion de espacios o uso de minusculas. Valores 'HI' y 'Q' no estan consignados en el manual del INF. ??????????\n",
    "DANO = u'DANO' # Daño registrado (str: 'Q', 'DB', 'SD', 'DM', 'IRR', 'EB'). Valor 'IRR' no esta consignado en el manual del INF.?????\n",
    "COND = u'CONDICION' # Condicion del individuo (str, 'MP', 'TO', 'VP', 'MC', 'M'). Valores TO, MC y M no estan consignados en el manual del INF. Que hacen individuos vivos (VP) en esta tabla?????\n",
    "BRIG = u'TIPO_BRIGADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logbuffer = u\"\\n\" + u\"#\" * 50 + u\"\\nTABLA VEGETACION\\n\"\n",
    "for fi in [PLOT, SPF, IND]:\n",
    "    if inds[fi].dtype != np.int64:\n",
    "        logbuffer += u\"\\nCampo {0} tiene tipo inapropiado ({1} en vez de int64).\\n\".format(\n",
    "            fi, inds[fi].dtype)\n",
    "        if len(inds[fi][det[fi].isna()]) > 1:\n",
    "            logbuffer += u\"\\nValores nulos son considerados np.float64:\\n\"\n",
    "            logbuffer += inds[[fi, PLOT, SPF, IND]][inds[fi].isna()].to_string(\n",
    "                            index = False) + \"\\n\"\n",
    "        else:\n",
    "            logbuffer += u\"\\nValores np.float64 a revisar:\\n\"\n",
    "            logbuffer += inds[fi, PLOT, SPF, IND][inds[fi].map(lambda x: x % 1.0 != 0)].dropna(\n",
    "                            ).to_string(index = False) + \"\\n\"\n",
    "            \n",
    "        \n",
    "for fi in [AZIMUT, DIST, DAP1, DAP2, ALTT, ALTF, PI_cm, PI_golpes, POM]:\n",
    "    if inds[fi].dtype != np.float64:\n",
    "        logbuffer += u\"\\nCampo {0} tiene tipo inapropiado ({1}en vez de float64).\\n\".format(\n",
    "            fi, inds[fi].dtype)\n",
    "\n",
    "for fi in [FAMILIA, GENERO, EPITETO, TAMANO, ALT_EQUIPO, DAP_EQUIPO, FORMA_FUSTE, DANO]:\n",
    "    non_strings = inds[fi].dropna()[~inds[fi].dropna().apply(type).eq(unicode)]\n",
    "    if len(non_strings):\n",
    "        logbuffer += u\"\\nCampo {0} tiene tipo inapropiado ({1} en vez de unicode).\\n\".format(\n",
    "            fi, non_strings.dtype)\n",
    "\n",
    "if interactive:\n",
    "    print logbuffer \n",
    "    logbuffer = u\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "# Segregar datos de control de calidad de brigadas regulares\n",
    "######################################################################################\n",
    "\n",
    "#\n",
    "# Incluir datos de control de calidad en la base de datos.\n",
    "#\n",
    "\n",
    "inds[BRIG].unique()\n",
    "qa = inds[inds[BRIG] == u\"calidad\"]\n",
    "inds = inds[inds[BRIG] == u\"estandar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "# Homogenización de información de información registrada para individuos de multiples\n",
    "# tallos: azimut y distancias están registrados en unos registros, diámetros en otros\n",
    "######################################################################################\n",
    "inds[(inds[TIPO1] == \"multiple\")][[PLOT, SPF, IND, NFUSTE, TIPO1, TIPO2, ALTT, DAP1, DAP2]]\n",
    "inds[(inds[TIPO1] == \"multiple\")].iloc[:,:20]\n",
    "\n",
    "for row in inds[inds[TIPO1] == \"multiple\"][[PLOT, SPF, IND, AZIMUT, DIST, TIPO2]].itertuples():\n",
    "    if row[6] == \"individuo\":\n",
    "        inds.loc[(inds[PLOT] == row[1]) & (inds[SPF] == row[2]) & (inds[IND] == row[3]) , AZIMUT] = row[4]\n",
    "        inds.loc[(inds[PLOT] == row[1]) & (inds[SPF] == row[2]) & (inds[IND] == row[3]) , DIST] = row[5]\n",
    "\n",
    "inds.drop(inds[(inds[TIPO1] == \"multiple\") & (inds[TIPO2] == \"individuo\")].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "# Individuos únicos usualmente no tienen número de fuste. A todos ellos se asigna 1\n",
    "# en dicho campo\n",
    "######################################################################################\n",
    "\n",
    "fustesnan = inds[inds[NFUSTE].isna()][[PLOT, SPF, IND]]\n",
    "fustesnan = fustesnan.merge(inds, on=[PLOT, SPF, IND], how='left').groupby([PLOT, SPF, IND]).size().reset_index()\n",
    "fustesnan.drop(labels=fustesnan[fustesnan[0] > 1].index, inplace = True)\n",
    "for row in fustesnan.itertuples():\n",
    "    inds.loc[((inds[PLOT] == row[1]) & (inds[SPF] == row[2]) & (inds[IND] == row[3])), NFUSTE] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "# Ahora se remueven los individuos duplicados. La version 2018 del reporte de la BD \n",
    "# maestra no contiene un indice unico de fuste, así que es necesario estimarlo \n",
    "# indirectamente usando el índice de conglomerado, de subparcela, de individuo y de fuste. \n",
    "# Cuando los registros duplicados no difieren en ninguna medida (azimut, daps, alturas,\n",
    "# etc.) se conserva el primer registro duplicado, de lo contrario se eliminan todos \n",
    "# los duplicados.\n",
    "######################################################################################\n",
    "inds.loc[inds[NFUSTE].isna(), NFUSTE] = -1 # valores np.nan no son agrupados por `groupby`\n",
    "dupfustes = inds.groupby([PLOT, SPF, IND, NFUSTE]).size().reset_index()\n",
    "toremove = []\n",
    "for row in dupfustes[dupfustes[0] > 1].itertuples():\n",
    "    thdups = inds[(inds[PLOT] == row[1]) & (inds[SPF] == row[2]) & (inds[IND] == row[3]) &\n",
    "         (inds[NFUSTE] == row[4])]\n",
    "    toremove += thdups.index.tolist()\n",
    "    \n",
    "    if thdups[thdups.duplicated()].shape[0] == 1:\n",
    "        toremove.remove(thdups[thdups.duplicated()].index.tolist()[0])\n",
    "        \n",
    "inds.drop(labels=toremove, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# \n",
    "# Ecuación alométrica diámetro-altura\n",
    "#\n",
    "#####################################################\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "%matplotlib tk\n",
    "\n",
    "# log(h) = a*log(d) + b\n",
    "\n",
    "def hei(dap, a, b):\n",
    "    return np.exp(a * np.log(dap) + b)\n",
    "\n",
    "def loghei(dap, a, b):\n",
    "    return a * np.log(dap) + b\n",
    "\n",
    "curve_fit(loghei, inds[inds[DAP1].notna() & inds[ALTT].notna()][DAP1].as_matrix(), \n",
    "    np.log(inds[inds[DAP1].notna() & inds[ALTT].notna()][ALTT].as_matrix()))\n",
    "\n",
    "\n",
    "plt.plot(np.linspace(0, 10, 100), map(lambda x: loghei(x, 0.48534394,  0.96669865), np.exp(np.linspace(0, 10, 100))))\n",
    "plt.plot(np.linspace(0, 10, 100), map(lambda x: loghei(x, 0.48534394,  1.92), np.exp(np.linspace(0, 10, 100))))\n",
    "plt.plot(np.linspace(0, 10, 100), map(lambda x: loghei(x, 0.48534394,  0), np.exp(np.linspace(0, 10, 100))))\n",
    "plt.plot(np.log(inds[inds[DAP1].notna() & inds[ALTT].notna()][DAP1].as_matrix()), np.log(inds[inds[DAP1].notna() & inds[ALTT].notna()][ALTT]), 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for spf in inds[SPF].unique():\n",
    "    if spf not in range(1,6):\n",
    "        logbuffer += u\"\\nValor no valido de parcela: {0}\\n\".format(spf)\n",
    "\n",
    "inds[TAMANO] = inds[TAMANO].str.upper()\n",
    "for tam in inds[TAMANO].unique():\n",
    "    if tam not in [u'B', u'L', u'F', u'FG']:\n",
    "        logbuffer += u\"\\nValor no valido de tamaño de individuo: {0}\\n\".format(tam)\n",
    "        \n",
    "if inds[AZIMUT].min() < 0:\n",
    "    logbuffer += u\"\\nAzimut contiene valores no aceptados (< 0).\\n\"\n",
    "\n",
    "if inds[AZIMUT].max() > 360:\n",
    "    logbuffer += u\"\\nAzimut contiene valores no aceptados (> 360):\\n\"\n",
    "    \n",
    "    logbuffer += inds[inds[AZIMUT] > 360][[PLOT, SPF, IND, AZIMUT]].to_string(index=False) + \"\\n\"\n",
    "    \n",
    "    inds.loc[inds[AZIMUT] > 360, AZIMUT] = 360\n",
    "    \n",
    "#################################################\n",
    "# Alturas\n",
    "# ¿Que hacer con brinzales de altura mayor a 1 m?\n",
    "# Brinzales de altura menor a 30 cm o 0?\n",
    "#################################################\n",
    "# Altura de brinzales deben ser menores a 2 m\n",
    "if inds[(inds[TAMANO] == u'B') & (inds[ALTT] > 2)].shape[0] > 0:\n",
    "    logbuffer += u\"\\nBrinzales con alturas sospechosas (> 2m):\\n\"\n",
    "    \n",
    "    logbuffer += inds[(inds[TAMANO] == u'B') & (inds[ALTT] > 2)][[PLOT, SPF, IND, TAMANO, \n",
    "        ALTT]].to_string(index=False) + \"\\n\"\n",
    "\n",
    "    inds.loc[(inds[TAMANO] == u'B') & (inds[ALTT] > 10), ALTT] /= 100.0\n",
    "    inds.loc[(inds[TAMANO] == u'B') & (inds[ALTT] > 2), ALTT] /= 10.0\n",
    "\n",
    "if inds[(inds[TAMANO] != u'B') & (inds[ALTT] > 50)].shape[0] > 0:\n",
    "    logbuffer += u\"\\nIndividuos con alturas sospechosas (> 50m):\\n\"\n",
    "    \n",
    "    logbuffer += inds[(inds[TAMANO] != u'B') & (inds[ALTT] > 50)][[PLOT, SPF, IND, TAMANO, \n",
    "        ALTT]].to_string(index=False) + \"\\n\"\n",
    "    \n",
    "    inds.loc[(inds[ALTT] >= 50) & ((inds[ALTT] / 10.0) > inds[ALTF]), ALTT ] = inds[\n",
    "        (inds[ALTT] >= 50) & ((inds[ALTT] / 10.0) > inds[ALTF])][ALTT] / 10.0\n",
    "\n",
    "    toswap = inds[((inds[ALTT] >= 50) | (inds[ALTF] >= 50)) & (inds[DAP1] < 20.0)].index\n",
    "    inds.loc[toswap , ALTT] /= 10.0\n",
    "    inds.loc[toswap , ALTF] /= 10.0\n",
    "\n",
    "    inds.drop(inds[inds[ALTT] > 60].index, inplace=True)\n",
    "\n",
    "# Verificar asignacion de clases diametricas\n",
    "\n",
    "inds.loc[((inds[TAMANO] != u'b') & ((inds[ALTT] > 0.3) & (inds[DAP1] < 2.5))), DAP1] *= 10\n",
    "inds.loc[((inds[TAMANO] != u'b') & ((inds[ALTT] > 0.3) & (inds[DAP2] < 2.5))), DAP2] *= 10\n",
    "\n",
    "inds[DAPA] = inds[[DAP1, DAP2]].mean(axis=1)\n",
    "if len(inds[(inds[TAMANO] != u'B') & (inds[DAPA] < 2.5)]):\n",
    "\n",
    "    logbuffer += u\"\\nBrinzales están asignados a categoria erronea:\\n\"\n",
    "\n",
    "    logbuffer += inds[[PLOT, SPF, IND, TAMANO, DAP1, DAP2, ALTT]][(inds[TAMANO] != u'B') \n",
    "                    & (inds[DAPA] < 2.5)].to_string(index=False) + \"\\n\"\n",
    "\n",
    "    inds.loc[(inds[TAMANO] != u'B') & (inds[DAPA] < 2.5), TAMANO] = u'B'\n",
    "    \n",
    "if len(inds[(inds[TAMANO] != u'L') & (inds[DAPA] < 10) & (inds[DAPA] >= 2.5)]):\n",
    "    \n",
    "    logbuffer += u\"\\nLatizales están asignados a categoria erronea:\\n\"\n",
    "    \n",
    "    logbuffer += inds[[PLOT, SPF, IND, TAMANO, DAP1, DAP2, ALTT]][(inds[TAMANO] != u'L') \n",
    "        & (inds[DAPA] < 10) & (inds[DAPA] >= 2.5)].to_string(index= False) + \"\\n\"\n",
    "    \n",
    "    inds.loc[(inds[TAMANO] != u'L') & (inds[DAPA] < 10) & (inds[DAPA] >= 2.5), TAMANO] = u'L'\n",
    "    \n",
    "if len(inds[(inds[TAMANO] != u'F') & (inds[DAPA] < 30) & (inds[DAPA] >= 10)]):\n",
    "    \n",
    "    logbuffer += u\"\\nFustales están asignados a categoria erronea:\\n\"\n",
    "    \n",
    "    logbuffer += inds[[PLOT, SPF, IND, TAMANO, DAP1, DAP2, ALTT]][(inds[TAMANO] != u'F') & \n",
    "        (inds[DAPA] < 30) & (inds[DAPA] >= 10)].to_string(index=False) + \"\\n\"\n",
    "    \n",
    "    inds.loc[(inds[TAMANO] != u'F') & (inds[DAPA] < 30) & (inds[DAPA] >= 10), TAMANO] = u'F'\n",
    "    \n",
    "if len(inds[(inds[TAMANO] != u'FG') & (inds[DAPA] >= 30)]):\n",
    "    \n",
    "    logbuffer += u\"\\nFustales grandes están asignados a categoria erronea:\\n\"\n",
    "    \n",
    "    logbuffer += inds[[PLOT, SPF, IND, TAMANO, DAP1, DAP2, ALTT]][(inds[TAMANO] != u'FG') \n",
    "        & (inds[DAPA] >= 30)].to_string(index = False) + \"\\n\"\n",
    "    \n",
    "    inds.loc[(inds[TAMANO] != u'FG') & (inds[DAPA] >= 30), TAMANO] = u'FG'\n",
    "    \n",
    "# Eliminar individuos sin informacion necesaria para asignar clase diametrica\n",
    "inds.drop(inds[~inds[TAMANO].isin([u'B', u'L', u'F', u'FG'])].index, inplace = True)\n",
    "\n",
    "# Verificar si las distancias corresponden a las categorias de edad.\n",
    "# Latizales y Fustales afuera de su area de medición son eliminados\n",
    "if len(inds[(inds[DIST] > 3) & (inds[TAMANO] == u'L')]):\n",
    "    \n",
    "    logbuffer += u\"\\nLatizales registrados afuera del area aceptada:\\n\"\n",
    "    \n",
    "    logbuffer += inds[[TAMANO, DIST, PLOT, SPF, IND]][(inds[DIST] > 3) & (inds[TAMANO] == u'L')\n",
    "        ].to_string(index=False) + \"\\n\"\n",
    "    \n",
    "    inds.drop(inds[(inds[DIST] > 3) & (inds[TAMANO] == u'L')].index, inplace=True)\n",
    "    \n",
    "if len(inds[(inds[DIST] > 7) & (inds[TAMANO] == u'F')]):\n",
    "    \n",
    "    logbuffer += u\"\\nFustales registrados afuera del area aceptada:\\n\"\n",
    "    \n",
    "    logbuffer += inds[[TAMANO, DIST, PLOT, SPF, IND]][(inds[DIST] > 7) & (inds[TAMANO] == u'F')\n",
    "        ].to_string(index=False) + \"\\n\"\n",
    "    \n",
    "    inds.drop(inds[(inds[DIST] > 7) & (inds[TAMANO] == u'F')].index, inplace=True)\n",
    "    \n",
    "if len(inds[inds[DIST] > 15]):\n",
    "    \n",
    "    logbuffer += u\"\\nIndividuos registrados afuera del area de la subparcela:\\n\"\n",
    "    \n",
    "    logbuffer += inds[[TAMANO, DIST, PLOT, SPF, IND]][inds[DIST] > 15].to_string(index=\n",
    "                    False) + \"\\n\"\n",
    "    \n",
    "    inds.drop(inds[inds[DIST] > 15].index, inplace = True)\n",
    "\n",
    "# Altura total siempre debe ser mayor a la altura del fuste\n",
    "if inds[inds[ALTF] > inds[ALTT]].size:\n",
    "    \n",
    "    logbuffer += u\"\\nIndividuos con altura del fuste mayor a la altura total:\\n\"\n",
    "    \n",
    "    logbuffer += inds[[ALTF, ALTT, PLOT, SPF, IND]][inds[ALTF] > inds[ALTT]].to_string(index\n",
    "                    =False) + \"\\n\"\n",
    "    \n",
    "    indexes = inds[inds[ALTF] > inds[ALTT]].index\n",
    "    myaltt = inds.loc[indexes, ALTT].copy()\n",
    "    inds.loc[indexes, ALTT] = inds.loc[indexes, ALTF]\n",
    "    inds.loc[indexes, ALTF] = myaltt\n",
    "    \n",
    "# Verificar determinaciones incongruentes entre tallos de individuos multiples\n",
    "indsppcount = inds.groupby([PLOT, SPF, IND, GENERO, EPITETO]).size().reset_index()\n",
    "indcount = indsppcount.groupby([PLOT, SPF, IND]).size().reset_index().rename(columns={0:u'dups'})\n",
    "if len(indcount[indcount.dups > 1]):\n",
    "    \n",
    "    logbuffer += u\"\\nIndividuos de tallos multiples con determinaciones de varias especies:\\n\"\n",
    "    \n",
    "    logbuffer += indcount[indcount[u'size'] > 1].to_string(index = False) + u\"\\n\"\n",
    "\n",
    "\n",
    "# Informacion Penetrometro\n",
    "if inds[PI_cm].min() < 0:\n",
    "    \n",
    "    logbuffer += u\"\\nHay valores negativos de entrada del penetrometro.\\n\"\n",
    "    \n",
    "if inds[PI_cm].max() > 20:\n",
    "    \n",
    "    logbuffer += u\"\\nValores maximos del entrada del penetrometro mayores al valor sugerido\" \\\n",
    "                    +  u\"en el manual:\\n\"\n",
    "\n",
    "    logbuffer += inds[[PI_cm, PLOT, SPF, IND]][inds[PI_cm] > 20].to_string(index=False) + u\"\\n\"\n",
    "    \n",
    "    # Valores mayores a 20 cm son reestablecidos a 20 cm\n",
    "    inds.loc[inds[PI_cm] > 20 , PI_cm] = 20\n",
    "\n",
    "if len(inds[PI_cm][(inds[PI_cm] > inds[DAP1]) | (inds[PI_cm] > inds[DAP2])]):\n",
    "    \n",
    "    logbuffer += u\"\\nValores de entrada del penetrómetro son mayores al diametro registrado:\\n\"\n",
    "    \n",
    "    logbuffer += inds[[PI_cm, DAP1, DAP2, PLOT, SPF, IND]][(inds[PI_cm] > inds[DAP1]) | (inds[PI_cm] \n",
    "                    > inds[DAP2])].to_string(index=False) + u\"\\n\"\n",
    "    \n",
    "    # Se asume que la medida del penetrometro equivale al diametro\n",
    "    inds.loc[(inds[PI_cm] > inds[DAP1]), PI_cm] = inds[DAP1][(inds[PI_cm] > inds[DAP1])]\n",
    "\n",
    "if inds[PI_golpes].min() < 0:\n",
    "    \n",
    "    logbuffer += u\"\\nValores negativos de golpes al penetrometro.\\n\"\n",
    "    \n",
    "if inds[PI_golpes].max() > 25:\n",
    "    \n",
    "    logbuffer += u\"\\nValores maximos de golpes del penetrometro son dudosos:\\n\"\n",
    "    \n",
    "    logbuffer += inds[[PI_golpes, PLOT, SPF, IND]][inds[PI_golpes] > 20].to_string(index=False) + u\"\\n\"\n",
    "\n",
    "######################################################################################\n",
    "# Depuración de nombres científicos\n",
    "# Se eliminan los valores no válidos y se trata de indagar los valores apropiados \n",
    "# basados en los valores de las tres celdas.\n",
    "######################################################################################\n",
    "\n",
    "inds.loc[(inds[FAMILIA] == u\"indeterminada\") | (inds[FAMILIA] == u\"tocón\") | (inds[FAMILIA] == u\"desconocido\"), FAMILIA] = np.nan\n",
    "inds.loc[:, FAMILIA] = inds[FAMILIA].str.replace(\"(\\w+)acea$\", \"\\1aceae\")\n",
    "inds.loc[inds[FAMILIA] == u\"pitherellobium\", GENERO]= \"Pithecellobium\"\n",
    "inds.loc[inds[FAMILIA] == u\"pitherellobium\", FAMILIA]= \"Fabaceae\"\n",
    "inds.loc[inds[FAMILIA].notna() & (inds[FAMILIA].str.contains(\"aceae$\") == False), FAMILIA] = np.nan\n",
    "\n",
    "inds.loc[(inds[GENERO].notna() & inds[GENERO].str.contains(\"indet\")) , GENERO] = np.nan\n",
    "indxs = inds[inds[GENERO].notna() & inds[GENERO].str.contains(\"\\s+\")].index\n",
    "for row in inds.loc[indxs, [FAMILIA, GENERO, EPITETO]].itertuples():\n",
    "    bits = re.split(\"\\s+\", row[2])\n",
    "    inds.loc[row[0], GENERO] = bits[0]\n",
    "\n",
    "inds.loc[:, EPITETO] = inds[EPITETO].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "inds.loc[:, EPITETO] = inds[EPITETO].str.replace(\"^\\s+(\\w+)$\", \"\\1\")\n",
    "inds.loc[:, EPITETO] = inds[EPITETO].str.replace(\"^(\\w+)\\s$\", \"\\1\")\n",
    "inds[\"bits\"] = inds[EPITETO].str.split(\"\\s+\")\n",
    "for row in inds[[GENERO, \"bits\"]].itertuples():\n",
    "    #print row[1], row[2]\n",
    "    if pd.notna(row[1]) and isinstance(row[2], list) and len(row[2]) > 1:\n",
    "        if row[1] == row[2][0]:\n",
    "            inds.loc[row[0], EPITETO] = row[2][1]\n",
    "        else:\n",
    "            inds.loc[row[0], GENERO] = row[2][0]\n",
    "            inds.loc[row[0], EPITETO] = row[2][1]\n",
    "inds.loc[(inds[EPITETO].notna() & inds[EPITETO].str.contains(\"indet\")) , EPITETO] = np.nan            \n",
    "inds.loc[(inds[EPITETO].notna() & inds[EPITETO].str.contains(\"^sp\\d*$\")) , EPITETO] = np.nan\n",
    "inds.loc[(inds[EPITETO].notna() & inds[EPITETO].str.contains(\"\\d\")) , EPITETO] = np.nan\n",
    "inds.loc[inds[EPITETO].notna() & inds[EPITETO].str.contains(\"\\s\"), EPITETO] = np.nan\n",
    "inds.loc[:, FAMILIA] = inds[FAMILIA].str.title()\n",
    "inds.loc[:, GENERO] = inds[GENERO].str.title()\n",
    "inds.loc[:, EPITETO] = inds[EPITETO].str.lower()\n",
    "\n",
    "inds[u\"Brigada\"] = u\"Estandar\"\n",
    "\n",
    "if interactive:\n",
    "    print logbuffer \n",
    "else:\n",
    "    with cd.open(logfile, mode='a', encoding=\"utf-8\") as fhandle:\n",
    "        fhandle.write(logbuffer)\n",
    "logbuffer = u\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CONSC = u'Cons' # Indice coordenada (int64)\n",
    "PLOTC = u'codigo_conglomerado' # Indice conglomerado (int64)\n",
    "SPFC = u'codigo_subparcela' # Indice subparcela dentro del conglomerado (int64 1-5)\n",
    "#SUBPLOT = u'SUBPLOT' # Concatenacion PLOT \"_\" SPF (str)\n",
    "LATITUD = u'latitud' # Latitud en formato decimal (float64)\n",
    "LONGITUD = u'longitud' # Longitud en formato decimal (float64)\n",
    "#REGION = u'REGION' # Region biogeografica (str: 'Amazonia', 'Andes', 'Pacifico', 'Orinoquia',\n",
    "                  # 'Caribe')\n",
    "#ZV = u'ZV' # Zona de vida???????? (int64, 3, 4, 5, 6, 7, 13, 14, 15, 19, 20, 21, 27)\n",
    "#ZONA_VIDA = u'ZONA_VIDA' # Zona de vida (str: \"Bosque húmedo tropical\",  \n",
    "    # \"Bosque muy húmedo tropical\",  \"Bosque húmedo montano bajo\",  \"Bosque pluvial premontano\",  \n",
    "    # \"Bosque muy húmedo premontano\",  \"Bosque húmedo premontano\",  \"Bosque muy húmedo montano\",  \n",
    "    # \"Bosque seco tropical\",  \"Bosque muy húmedo montano bajo\",  \"Bosque seco montano bajo\",  \n",
    "    # \"Bosque muy seco tropical\",  \"Monte espinoso subtropical\")\n",
    "#EQ = u'EQ' # Ecuacion alometrica???? (int64: 1, 2, 4, 5, 6)\n",
    "#E_CHAVE = u'E_CHAVE' # Coeficiente de la ecuacion de Chave (float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logbuffer = u\"\\n\" + u\"#\" * 50 + u\"\\nTABLA COORDENADAS\\n\"\n",
    "\n",
    "for fi in [PLOTC, SPFC]:\n",
    "    \n",
    "    if coord[fi].dtype != np.int64:\n",
    "        \n",
    "        logbuffer += u\"\\nCampo {0} tiene tipo inapropiado ({1} en vez de int64).\\n\".format(\n",
    "                        fi, coord[fi].dtype)\n",
    "        \n",
    "        if len(coord[fi][coord[fi].isna()]) > 1:\n",
    "            \n",
    "            logbuffer += u\"\\nLos siguentes valores nulos son considerados np.float64 por Pandas:\\n\"\n",
    "            \n",
    "            logbuffer += coord[[fi, PLOTC, SPFC]][amp[fi].isna()].to_string(index=False) + u\"\\n\"\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            logbuffer += u\"\\nValores np.float64 a revisar:\\n\"\n",
    "            \n",
    "            logbuffer += coord[[fi, PLOTC, SPFC]][coord[fi].map(lambda x: x % 1.0 != 0)].dropna(\n",
    "                            ).to_string(index=False) + u\"\\n\"\n",
    "            \n",
    "            \n",
    "for fi in [LATITUD, LONGITUD]:\n",
    "    \n",
    "    if coord[fi].dtype != np.float64:\n",
    "        \n",
    "        logbuffer += u\"\\nCampo {0} tiene tipo inapropiado ({1} en vez de float64)\\n.\".format(\n",
    "                        fi, coord[fi].dtype)\n",
    "        \n",
    "if interactive:\n",
    "    print logbuffer\n",
    "    logbuffer = u\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verificar que los indices no están duplicados\n",
    "if len(coord[coord[[PLOTC, SPFC]].duplicated()]):\n",
    "    logbuffer += u\"\\nTabla {0} contiene indices duplicados\\n.\".format(coordenadas)\n",
    "\n",
    "# Verificar rangos de coordenadas \n",
    "lat_range = (-5, 15)\n",
    "lon_range = (-80, -65)\n",
    "\n",
    "if coord[LATITUD].min() < lat_range[0] or coord[LATITUD].max() > lat_range[1]:\n",
    "    \n",
    "    logbuffer +=  \"\\nLatitud fuerra de rango aceptado.\\n\"\n",
    "    \n",
    "if coord[LONGITUD].min() < lon_range[0] or coord[LONGITUD].max() > lon_range[1]:\n",
    "    \n",
    "    logbuffer +=  \"\\nLongitud fuerra de rango aceptado\\n\"\n",
    "\n",
    "# Verificar que todas las parcelas están georeferenciadas\n",
    "integ = inds[[PLOT, SPF]].merge(coord[[PLOTC, SPFC, LATITUD, LONGITUD]].rename(columns = \n",
    "    {PLOTC:PLOT, SPFC:SPF}), on=[PLOT,SPF], how='left')\n",
    "\n",
    "if len(integ[integ[LATITUD].isna() | integ[LONGITUD].isna()]):\n",
    "    \n",
    "    logbuffer +=  \"\\nAlgunas parcelas no tienen coordenadas geograficas:\\n\"\n",
    "    \n",
    "    logbuffer += integ[integ[LATITUD].isna() | integ[LONGITUD].isna()].to_string(index=\n",
    "                    False) + u\"\\n\"\n",
    "    \n",
    "if interactive:\n",
    "    print logbuffer \n",
    "else:\n",
    "    with open(logfile, 'a') as fhandle:\n",
    "        fhandle.write(logbuffer)\n",
    "logbuffer = u\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inclusion de información en la base de datos\n",
    "Se incluyen los datos depurados en la base de datos MySQL a través del módulo SQLAlchemy. El esquema de la base de datos debe ser incluido con anterioridad al servidor local. Una copia del esquema está disponible en el archivo `Esquema_Inventario.sql`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as al\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from credentials import mysql_db\n",
    "\n",
    "engine = al.create_engine(\n",
    "    'mysql+mysqldb://{0}:{1}@localhost/IFN_2018?charset=utf8&use_unicode=1&unix_socket=/var/run/mysqld/mysqld.sock'.format(mysql_db['username'], mysql_db['password']), encoding='utf-8')\n",
    "#    'mysql+mysqldb://{0}:{1}@localhost/IFN_2018?charset=utf8&use_unicode=1'.format(mysql_db['username'], mysql_db['password']), encoding='utf-8')\n",
    "\n",
    "con = engine.connect()\n",
    "\n",
    "# Desactivar la verificación de foreign keys para la inserción en lote\n",
    "#con.execute('SET foreign_key_checks = 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tabla Coordenadas\n",
    "\n",
    "coord[[PLOTC, SPFC, LATITUD, LONGITUD]].rename(columns = {PLOTC: u'Plot', SPFC: u'SPF', LATITUD:\n",
    "    u'Latitud', LONGITUD: u'Longitud'}).to_sql('Coordenadas', con, if_exists = 'append', \n",
    "    index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tabla Taxonomia\n",
    "\n",
    "tax = {}\n",
    "\n",
    "for row in inds[[FAMILIA, GENERO, EPITETO]].itertuples():\n",
    "    tax[(row[1], row[2], row[3])] = 0\n",
    "    \n",
    "taxtemp = {FAMILIA:[], GENERO:[], EPITETO:[]}\n",
    "\n",
    "for (fam, gen, epi) in tax:\n",
    "    taxtemp[FAMILIA].append(fam)\n",
    "    taxtemp[GENERO].append(gen)\n",
    "    taxtemp[EPITETO].append(epi)\n",
    "    #axtemp[AUTOR].append(tax[(fam, gen, epi)])\n",
    "\n",
    "tax = None\n",
    "taxdf = pd.DataFrame.from_dict(taxtemp)\n",
    "taxtemp = None\n",
    "\n",
    "if taxdf.index[0] == 0:\n",
    "    taxdf.index += 1\n",
    "    \n",
    "taxdf[u'Fuente'] = 1\n",
    "\n",
    "#\"\"\"\n",
    "taxdf.rename(columns = {FAMILIA: u'Familia', GENERO: u'Genero', EPITETO: u'Epiteto'} ).to_sql( \n",
    "    'Taxonomia', con, if_exists='append', index_label=u'TaxonID')\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tabla Determinaciones\n",
    "\n",
    "if u'Taxon' not in taxdf.columns:\n",
    "    taxdf[u'Taxon'] = taxdf.index\n",
    "\n",
    "if 'Taxon' not in inds:\n",
    "    inds = inds.merge(taxdf[[FAMILIA, GENERO, EPITETO, u'Taxon']], on=[FAMILIA, GENERO, EPITETO],\n",
    "            how='left', suffixes = [u'_l', u'_r'])\n",
    "\n",
    "deters = inds.groupby(by=[PLOT, SPF, IND, u'Taxon']).size().reset_index().drop(axis=1, labels=0)\n",
    "\n",
    "if deters.index[0] == 0:\n",
    "    deters.index += 1\n",
    "\n",
    "deters[u'DetID'] = deters.index\n",
    "deters[[u'Taxon', u'DetID']].to_sql('Determinaciones', con, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tabla individuos\n",
    "\n",
    "if u'DetID' not in inds.columns:\n",
    "    inds = inds.merge(deters[[PLOT, SPF, IND, u'DetID']], on=[PLOT, SPF, IND], how='left')\n",
    "\n",
    "inds.loc[inds[AZIMUT].isna() , AZIMUT] = u'NULO'\n",
    "inds.loc[inds[DIST].isna() , DIST] = u'NULO'\n",
    "trueinds = inds.groupby([PLOT, AZIMUT, IND, SPF, DIST, u'DetID', u'Brigada']).size().reset_index()\n",
    "trueinds.loc[trueinds[AZIMUT] == u'NULO' , AZIMUT] = np.nan\n",
    "trueinds.loc[trueinds[DIST] == u'NULO' , DIST] = np.nan\n",
    "inds.loc[inds[AZIMUT] == u'NULO' , AZIMUT] = np.nan\n",
    "inds.loc[inds[DIST] == u'NULO' , DIST] = np.nan\n",
    "\n",
    "if u'IndividuoID' not in trueinds.columns:\n",
    "    trueinds[u'IndividuoID'] = trueinds.index\n",
    "    trueinds[u'IndividuoID'] += 1\n",
    "    \n",
    "if u'Individuo' not in inds.columns:\n",
    "    inds = inds.merge(trueinds[[PLOT, SPF, IND, u'IndividuoID']], on = [PLOT, SPF, IND], how='left')\n",
    "\n",
    "#\"\"\"\n",
    "trueinds[[PLOT, AZIMUT, SPF, DIST, u'DetID', u'IndividuoID', u'Brigada']].rename(columns = {PLOT: u'Plot', \n",
    "    SPF: u'Subparcela', AZIMUT: u'Azimut', DIST: u'Distancia', u'DetID': u'Dets'}).to_sql(\n",
    "    'Individuos', con, if_exists = 'append', index = False)\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tabla Tallos\n",
    "\n",
    "if inds.index[0] == 0:\n",
    "    inds.index += 1\n",
    "\n",
    "#\"\"\"\n",
    "inds[[DAP1, DAP2, DAPA, TAMANO, ALTF, ALTT, u'IndividuoID', PI_cm, PI_golpes]].rename(columns = \n",
    "    {DAP1: u'Diametro1', DAP2: u'Diametro2', DAPA: u'DiametroP', TAMANO: u'Tamano', DANO: u\"DANO\",\n",
    "    ALTF: u'AlturaFuste', ALTT: u'AlturaTotal', u'IndividuoID': u'Individuo', PI_cm: u'PetrProf', \n",
    "    PI_golpes: u'PetrGolpes'}).to_sql(u'Tallos', con, if_exists = 'append', index = True, \n",
    "    index_label = u'TalloID')\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tabla Detritos\n",
    "\n",
    "\"\"\"\n",
    "PI_cm, PI_golpes = u'PI_cm', u'PI_golpes'\n",
    "\n",
    "det[[CONS, PLOT, TRAN, SECC, PIEZA, TIPO, DIST, AZIMUT, D1, D2, INCL, PI_cm, PI_golpes, \n",
    "    PESO_RODAJA, PESO_MUESTRA, PESO_SECO, ESP1, ESP2, ESP3, ESP4, VOL, DENS]].rename(\n",
    "    columns = {CONS: u'DETRITOID', PLOT: u'PLOT', TRAN: u'Transecto', SECC: u'Seccion', \n",
    "    PIEZA: u'Pieza', TIPO: u'Tipo', DIST: u'Distancia', AZIMUT: u'Azimut', D1: u'Diametro1', \n",
    "    D2: u'Diametro2', INCL: u'Inclinacion', PI_cm: u'PetrProf', PI_golpes: u'PetrGolpes',\n",
    "    PESO_RODAJA: u'PesoRodaja', PESO_MUESTRA: u'PesoMuestra', PESO_SECO: u'PesoSeco', \n",
    "    ESP1: u'Espesor1', ESP2: u'Espesor2', ESP3: u'Espesor3', ESP4: u'Espesor4', \n",
    "    VOL: u'Volumen', DENS: u'Densidad'}).to_sql(u'Detritos', con, \n",
    "    if_exists = 'append', index = False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cerrar conexion\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
