{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allometric equation uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import allometry\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Site', u'DBH_cm', u'Total_height_m', u'AGB_kg', u'Gravity'], dtype='object')\n",
      "Index([u'Abbreviation', u'Tree_count', u'2005_avail', u'Latitude',\n",
      "       u'Longitude', u'Locality', u'Forest_type', u'Successional_type',\n",
      "       u'Mean_annual_temperature', u'Temp_Seasonality', u'Mean_Annual_Precip',\n",
      "       u'Precip_Seasonality_perc', u'Altitude', u'Evapotranspiration_mm_yr',\n",
      "       u'Dry_months', u'CWD_mm_yr', u'Ref'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load harvest data from Chave et al 2014\n",
    "har = pd.read_csv(\"../Chave_harvest_db/Chave_GCB_Direct_Harvest_Data.csv\")\n",
    "loc = pd.read_csv(\"../Chave_harvest_db/Localities.csv\")\n",
    "loc['Forest_type'] = loc.Forest_type.str.replace(' forest','')\n",
    "print har.columns\n",
    "print loc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BraMan2', 'BraPara1', 'BraPara3', 'BraRond', 'ColombiaC1',\n",
       "       'ColombiaG1', 'ColombiaG2', 'ColombiaM1', 'ColombiaM2', 'CostaRic',\n",
       "       'FrenchGu', 'Llanosec', 'Llanosol', 'MFrenchG', 'Peru', 'SaoPaulo3',\n",
       "       'SouthBrazil1', 'SouthBrazil2', 'SouthBrazil3', 'Venezuela2'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select harvest data from South America\n",
    "sa = loc[loc.Locality.str.contains('Brazil') | loc.Locality.str.contains('Colombia') |\n",
    "         loc.Locality.str.contains('Venezuela') | loc.Locality.str.contains('Peru') |\n",
    "         loc.Locality.str.contains('French Guiana') | loc.Locality.str.contains('Costa Rica')\n",
    "        ]['Abbreviation'].tolist()\n",
    "\n",
    "sahar = har[har.Site.isin(sa)]\n",
    "sahar.Site.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allometric functions\n",
    "def est_alvarez(row):\n",
    "    return allometry.alvarez(row.DBH_cm, row.Gravity, row.Holdridge)\n",
    "\n",
    "def est_chaveI(row):\n",
    "    fo = loc[loc.Abbreviation == row.Site]['Forest_type'].item()\n",
    "    return allometry.chaveI(row.DBH_cm, row.Gravity, fo)\n",
    "\n",
    "def est_chaveI_or(row):\n",
    "    fo = loc[loc.Abbreviation == row.Site]['Forest_type'].item()\n",
    "    return allometry.chaveI_original(row.DBH_cm, row.Gravity, fo)\n",
    "\n",
    "def est_E(row):\n",
    "    #E = ( 0.178 × TS-0.938 × CWD-6.61× PS ) ×10 −3\n",
    "    ts = loc[loc.Abbreviation == row.Site]['Temp_Seasonality'].item()\n",
    "    cwd = loc[loc.Abbreviation == row.Site]['CWD_mm_yr'].item()\n",
    "    ps = loc[loc.Abbreviation == row.Site]['Precip_Seasonality_perc'].item()\n",
    "    E = (0.178 * ts - 0.938 * cwd - 6.61 * ps) * 1e-3\n",
    "    return E\n",
    "\n",
    "def est_holdr(row):\n",
    "    alt = loc[loc.Abbreviation == row.Site]['Altitude'].item()\n",
    "    prep = loc[loc.Abbreviation == row.Site]['Mean_Annual_Precip'].item()\n",
    "    return allometry.holdridge_col(alt, prep)\n",
    "\n",
    "def est_chaveII(row):\n",
    "    return allometry.chaveII(row.DBH_cm, row.Gravity, e_value = row.E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nelsonsalinas/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:357: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/nelsonsalinas/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "har['E'] = har.apply(est_E, axis=1)\n",
    "sahar.loc[:,'Holdridge'] = sahar.apply(est_holdr, axis=1)\n",
    "\n",
    "har['ChaveI'] = har.apply(est_chaveI, axis=1)\n",
    "har['ChaveI_or'] = har.apply(est_chaveI_or, axis=1)\n",
    "har['ChaveII'] = har.apply(est_chaveII, axis=1)\n",
    "sahar.loc[:,'Alvarez'] = sahar.apply(est_alvarez, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Estimate errors\n",
    "har['ChaveI_error'] = (np.log(har.ChaveI) - np.log(har.AGB_kg))**2\n",
    "har['ChaveI_or_error'] = (np.log(har.ChaveI_or) - np.log(har.AGB_kg))**2\n",
    "har['ChaveII_error'] = (np.log(har.ChaveII) - np.log(har.AGB_kg))**2\n",
    "sahar.loc[:,'Alvarez_error'] = (np.log(sahar.Alvarez) - np.log(sahar.AGB_kg))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.597036288929\n",
      "0.57808567889\n",
      "0.420779217764\n",
      "0.560882175149\n"
     ]
    }
   ],
   "source": [
    "# SEEs\n",
    "print (har.ChaveI_error.sum() / (har.shape[0]-4))**0.5\n",
    "print (har.ChaveI_or_error.sum() / (har.shape[0]-4))**0.5\n",
    "print (har.ChaveII_error.sum() / (har.shape[0]-5))**0.5\n",
    "print (sahar.Alvarez_error.sum() / (sahar.shape[0]-5))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit equation via least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chave2005(X, a, b, c, d):\n",
    "    dap, den = X\n",
    "    out = a + b * np.log(dap) + c * np.log(dap)**2 + d * np.log(dap)**3 + np.log(den)\n",
    "    return out\n",
    "\n",
    "def chave2014(X, a, b, c, d, e):\n",
    "    E, den, dap = X\n",
    "    out = a + b * E + c * np.log(den) + d * np.log(dap) + e * np.log(dap)**2\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-3.35030644,  3.68832942, -0.29566994,  0.02574888]),\n",
       " array([[ 0.12942566, -0.13359906,  0.04347523, -0.00448497],\n",
       "        [-0.13359906,  0.13954395, -0.04588297,  0.00477556],\n",
       "        [ 0.04347523, -0.04588297,  0.01523812, -0.00160049],\n",
       "        [-0.00448497,  0.00477556, -0.00160049,  0.00016959]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curve_fit(chave2005, (har.DBH_cm, har.Gravity), np.log(har.AGB_kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEE: 0.526537644398\n",
      "CF: 1.14868860187\n",
      "log CF: 0.138620945484\n"
     ]
    }
   ],
   "source": [
    "har['ChaveI_new'] = np.exp(chave2005((har.DBH_cm, har.Gravity), -3.350, 3.688, -0.296, 0.026))\n",
    "har['ChaveI_new_error'] = (np.log(har.ChaveI_new) - np.log(har.AGB_kg))**2\n",
    "cf = har.ChaveI_new_error.sum() / (har.shape[0]-4)\n",
    "print \"SEE:\", cf ** 0.5\n",
    "print \"CF:\", np.exp(cf / 2)\n",
    "print \"log CF:\", cf / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-2.10942259, -0.89647401,  0.92284733,  2.79430146, -0.04585078]),\n",
       " array([[  6.98923097e-03,  -2.73651475e-04,   2.46197208e-04,\n",
       "          -4.58184091e-03,   7.17341406e-04],\n",
       "        [ -2.73651475e-04,   3.65234170e-04,  -1.09504322e-04,\n",
       "           6.04247529e-05,  -2.83776447e-06],\n",
       "        [  2.46197208e-04,  -1.09504322e-04,   5.41010476e-04,\n",
       "           1.22203572e-05,   1.06427576e-06],\n",
       "        [ -4.58184091e-03,   6.04247529e-05,   1.22203572e-05,\n",
       "           3.16582330e-03,  -5.07408790e-04],\n",
       "        [  7.17341406e-04,  -2.83776447e-06,   1.06427576e-06,\n",
       "          -5.07408790e-04,   8.33124928e-05]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curve_fit(chave2014, (har.E, har.Gravity, har.DBH_cm), np.log(har.AGB_kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEE: 0.415318493142\n",
      "CF: 1.0900730642\n",
      "log CF: 0.0862447253731\n"
     ]
    }
   ],
   "source": [
    "har['ChaveII_new'] = np.exp(chave2014((har.E, har.Gravity, har.DBH_cm), -2.109, -0.896,  0.923,  2.794, -0.046))\n",
    "har['ChaveII_new_error'] = (np.log(har.ChaveII_new) - np.log(har.AGB_kg))**2\n",
    "cf = har.ChaveII_new_error.sum() / (har.shape[0]-5)\n",
    "print \"SEE:\", cf ** 0.5\n",
    "print \"CF:\", np.exp(cf / 2)\n",
    "print \"log CF:\", cf / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum likelihood fit - Spicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logLike(true, guess):\n",
    "    n = len(true)\n",
    "    error = true - guess\n",
    "    sigma = np.std(error)\n",
    "    f = -(n/2.0)*np.log(2*np.pi) - (n/2.0) * np.log(sigma**2) - \\\n",
    "            (1.0/(2*sigma**2) * np.dot(error.T,error))\n",
    "    return f\n",
    "\n",
    "def opt_chave2005(pars):\n",
    "    y = pars[0] + pars[1] * np.log(har.DBH_cm) + pars[2] * np.log(har.DBH_cm)**2 + \\\n",
    "            pars[3] * np.log(har.DBH_cm)**3 + np.log(har.Gravity)\n",
    "    log = logLike(np.log(har.AGB_kg), y)\n",
    "    return -1 * log\n",
    "\n",
    "def opt_chave2014(pars):\n",
    "    y = pars[0] + pars[1] * har.E + pars[2] * np.log(har.Gravity) + pars[3] * np.log(har.DBH_cm) \\\n",
    "        + pars[4] * np.log(har.DBH_cm)**2 \n",
    "    log = logLike(np.log(har.AGB_kg), y)\n",
    "    return -1 * log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chave 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coeffs = np.array([-3.350, 3.688, -0.296, 0.026])\n",
    "coeffs = np.array([-2.350, 2.688, -1.296, 0.026])\n",
    "#opt_chave2005(coeffs)\n",
    "res = minimize(opt_chave2005, coeffs, method='BFGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chave 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coeffs = np.array([-2.109, -0.896,  0.923,  2.794, -0.046])\n",
    "coeffs = np.array([-3.109, -1.896,  1.923,  1.794, 1.046])\n",
    "res = minimize(opt_chave2014, coeffs, method='BFGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum likelihood fit\n",
    "### equation Chave I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mymodel = pymc3.Model()\n",
    "with mymodel:\n",
    "    #a + b * np.log(dap) + c * np.log(dap)**2 + d * np.log(dap)**3 + np.log(den)\n",
    "    a = pymc3.Uniform('a')\n",
    "    b = pymc3.Uniform('b')\n",
    "    c = pymc3.Uniform('c')\n",
    "    d = pymc3.Uniform('d')\n",
    "    #sigma = pymc3.Normal('sigma', mu=0, sd=0.4)\n",
    "    \n",
    "    y_exp = a + b * np.log(har.DBH_cm) + c * np.log(har.DBH_cm)**2 + d * np.log(har.DBH_cm)**3 + \\\n",
    "        np.log(har.Gravity)\n",
    "        \n",
    "    Y_obs = pymc3.Normal('Y_obs', mu=y_exp, sd=0.4, observed=np.log(har.AGB_kg))\n",
    "    \n",
    "    trace = pymc3.sample(5000, njobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pymc3.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_estimate = pymc3.find_MAP(model=mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_estimate\n",
    "# 0.1606, 1, 0.262888, 0 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
