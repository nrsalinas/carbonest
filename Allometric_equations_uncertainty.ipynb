{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allometric equation uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import allometry\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load harvest data from Chave et al 2014\n",
    "har = pd.read_csv(\"../Chave_harvest_db/Chave_GCB_Direct_Harvest_Data.csv\")\n",
    "loc = pd.read_csv(\"../Chave_harvest_db/Localities.csv\")\n",
    "loc['Forest_type'] = loc.Forest_type.str.replace(' forest','')\n",
    "print har.columns\n",
    "print loc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select harvest data from South America\n",
    "sa = loc[loc.Locality.str.contains('Brazil') | loc.Locality.str.contains('Colombia') |\n",
    "         loc.Locality.str.contains('Venezuela') | loc.Locality.str.contains('Peru') |\n",
    "         loc.Locality.str.contains('French Guiana') | loc.Locality.str.contains('Costa Rica')\n",
    "        ]['Abbreviation'].tolist()\n",
    "\n",
    "sahar = har[har.Site.isin(sa)]\n",
    "sahar.Site.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allometric functions\n",
    "def est_alvarez(row):\n",
    "    return allometry.alvarez(row.DBH_cm, row.Gravity, row.Holdridge)\n",
    "\n",
    "def est_chaveI(row):\n",
    "    fo = loc[loc.Abbreviation == row.Site]['Forest_type'].item()\n",
    "    return allometry.chaveI(row.DBH_cm, row.Gravity, fo)\n",
    "\n",
    "def est_chaveI_or(row):\n",
    "    fo = loc[loc.Abbreviation == row.Site]['Forest_type'].item()\n",
    "    return allometry.chaveI_original(row.DBH_cm, row.Gravity, fo)\n",
    "\n",
    "def est_E(row):\n",
    "    #E = ( 0.178 × TS-0.938 × CWD-6.61× PS ) ×10 −3\n",
    "    ts = loc[loc.Abbreviation == row.Site]['Temp_Seasonality'].item()\n",
    "    cwd = loc[loc.Abbreviation == row.Site]['CWD_mm_yr'].item()\n",
    "    ps = loc[loc.Abbreviation == row.Site]['Precip_Seasonality_perc'].item()\n",
    "    E = (0.178 * ts - 0.938 * cwd - 6.61 * ps) * 1e-3\n",
    "    return E\n",
    "\n",
    "def est_holdr(row):\n",
    "    alt = loc[loc.Abbreviation == row.Site]['Altitude'].item()\n",
    "    prep = loc[loc.Abbreviation == row.Site]['Mean_Annual_Precip'].item()\n",
    "    return allometry.holdridge_col(alt, prep)\n",
    "\n",
    "def est_chaveII(row):\n",
    "    return allometry.chaveII(row.DBH_cm, row.Gravity, e_value = row.E)\n",
    "\n",
    "def est_chaveII_dh(row):\n",
    "    return allometry.chaveII_dh(row.DBH_cm, row.Total_height_m, row.Gravity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logdh(diam, height, density):\n",
    "    return np.log(0.0673) + 0.976 * (np.log(density) + np.log(height) + 2 * np.log(diam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "har['E'] = har.apply(est_E, axis=1)\n",
    "sahar.loc[:,'Holdridge'] = sahar.apply(est_holdr, axis=1)\n",
    "\n",
    "har['ChaveI'] = har.apply(est_chaveI, axis=1)\n",
    "har['ChaveI_or'] = har.apply(est_chaveI_or, axis=1)\n",
    "har['ChaveII'] = har.apply(est_chaveII, axis=1)\n",
    "har['ChaveII_dh'] = har.apply(est_chaveII_dh, axis=1)\n",
    "sahar.loc[:,'Alvarez'] = sahar.apply(est_alvarez, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Estimate errors\n",
    "har['ChaveI_error'] = (np.log(har.ChaveI) - np.log(har.AGB_kg))**2\n",
    "har['ChaveI_or_error'] = (np.log(har.ChaveI_or) - np.log(har.AGB_kg))**2\n",
    "har['ChaveII_error'] = (np.log(har.ChaveII) - np.log(har.AGB_kg))**2\n",
    "har['ChaveII_dh_error'] = (np.log(har.ChaveII_dh) - np.log(har.AGB_kg))**2\n",
    "sahar.loc[:,'Alvarez_error'] = (np.log(sahar.Alvarez) - np.log(sahar.AGB_kg))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEEs\n",
    "print (har.ChaveI_error.sum() / (har.shape[0]-4))**0.5\n",
    "print (har.ChaveI_or_error.sum() / (har.shape[0]-4))**0.5\n",
    "print (har.ChaveII_error.sum() / (har.shape[0]-5))**0.5\n",
    "print (har.ChaveII_dh_error.sum() / (har.shape[0]-2))**0.5\n",
    "print (sahar.Alvarez_error.sum() / (sahar.shape[0]-5))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit equation via least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chave2005(X, a, b, c, d):\n",
    "    dap, den = X\n",
    "    out = a + b * np.log(dap) + c * np.log(dap)**2 + d * np.log(dap)**3 + np.log(den)\n",
    "    return out\n",
    "\n",
    "def chave2014(X, a, b, c, d, e):\n",
    "    E, den, dap = X\n",
    "    out = a + b * E + c * np.log(den) + d * np.log(dap) + e * np.log(dap)**2\n",
    "    return out\n",
    "\n",
    "def chave2014_dh(X, a, b):\n",
    "    dap, hei, den = X\n",
    "    out = np.log(a) + b * (np.log(den) + np.log(hei) + 2 * np.log(dap))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_fit(chave2005, (har.DBH_cm, har.Gravity), np.log(har.AGB_kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "har['ChaveI_new'] = np.exp(chave2005((har.DBH_cm, har.Gravity), -3.350, 3.688, -0.296, 0.026))\n",
    "har['ChaveI_new_error'] = (np.log(har.ChaveI_new) - np.log(har.AGB_kg))**2\n",
    "cf = har.ChaveI_new_error.sum() / (har.shape[0]-4)\n",
    "print \"SEE:\", cf ** 0.5\n",
    "print \"CF:\", np.exp(cf / 2)\n",
    "print \"log CF:\", cf / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_fit(chave2014, (har.E, har.Gravity, har.DBH_cm), np.log(har.AGB_kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "har['ChaveII_new'] = np.exp(chave2014((har.E, har.Gravity, har.DBH_cm), -2.109, -0.896,  0.923,  2.794, -0.046))\n",
    "har['ChaveII_new_error'] = (np.log(har.ChaveII_new) - np.log(har.AGB_kg))**2\n",
    "cf = har.ChaveII_new_error.sum() / (har.shape[0]-5)\n",
    "print \"SEE:\", cf ** 0.5\n",
    "print \"CF:\", np.exp(cf / 2)\n",
    "print \"log CF:\", cf / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_fit(chave2014_dh, (har.DBH_cm, har.Total_height_m, har.Gravity), np.log(har.AGB_kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "har['ChaveII_dh_new'] = np.exp(chave2014_dh((har.DBH_cm, har.Total_height_m, har.Gravity), 0.06311, 0.9759))\n",
    "har['ChaveII_dh_new_error'] = (np.log(har.ChaveII_dh_new) - np.log(har.AGB_kg))**2\n",
    "cf = har.ChaveII_dh_new_error.sum() / (har.shape[0]-2)\n",
    "print \"SEE:\", cf ** 0.5\n",
    "print \"CF:\", np.exp(cf / 2)\n",
    "print \"log CF:\", cf / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum likelihood fit - Spicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logLike(true, guess):\n",
    "    n = len(true)\n",
    "    error = true - guess\n",
    "    sigma = np.std(error)\n",
    "    f = -(n/2.0)*np.log(2*np.pi) - (n/2.0) * np.log(sigma**2) - \\\n",
    "            (1.0/(2*sigma**2) * np.dot(error.T,error))\n",
    "    return f\n",
    "\n",
    "def opt_chave2005(pars):\n",
    "    y = pars[0] + pars[1] * np.log(har.DBH_cm) + pars[2] * np.log(har.DBH_cm)**2 + \\\n",
    "            pars[3] * np.log(har.DBH_cm)**3 + np.log(har.Gravity)\n",
    "    log = logLike(np.log(har.AGB_kg), y)\n",
    "    return -1 * log\n",
    "\n",
    "def opt_chave2014(pars):\n",
    "    y = pars[0] + pars[1] * har.E + pars[2] * np.log(har.Gravity) + pars[3] * np.log(har.DBH_cm) \\\n",
    "        + pars[4] * np.log(har.DBH_cm)**2 \n",
    "    log = logLike(np.log(har.AGB_kg), y)\n",
    "    return -1 * log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chave 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coeffs = np.array([-3.350, 3.688, -0.296, 0.026])\n",
    "coeffs = np.array([-2.350, 2.688, -1.296, 0.026])\n",
    "#opt_chave2005(coeffs)\n",
    "res = minimize(opt_chave2005, coeffs, method='BFGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chave 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coeffs = np.array([-2.109, -0.896,  0.923,  2.794, -0.046])\n",
    "coeffs = np.array([-3.109, -1.896,  1.923,  1.794, 1.046])\n",
    "res = minimize(opt_chave2014, coeffs, method='BFGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum likelihood fit\n",
    "### equation Chave I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mymodel = pymc3.Model()\n",
    "with mymodel:\n",
    "    #a + b * np.log(dap) + c * np.log(dap)**2 + d * np.log(dap)**3 + np.log(den)\n",
    "    a = pymc3.Uniform('a')\n",
    "    b = pymc3.Uniform('b')\n",
    "    c = pymc3.Uniform('c')\n",
    "    d = pymc3.Uniform('d')\n",
    "    #sigma = pymc3.Normal('sigma', mu=0, sd=0.4)\n",
    "    \n",
    "    y_exp = a + b * np.log(har.DBH_cm) + c * np.log(har.DBH_cm)**2 + d * np.log(har.DBH_cm)**3 + \\\n",
    "        np.log(har.Gravity)\n",
    "        \n",
    "    Y_obs = pymc3.Normal('Y_obs', mu=y_exp, sd=0.4, observed=np.log(har.AGB_kg))\n",
    "    \n",
    "    trace = pymc3.sample(5000, njobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pymc3.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_estimate = pymc3.find_MAP(model=mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_estimate\n",
    "# 0.1606, 1, 0.262888, 0 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
