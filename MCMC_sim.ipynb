{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo simulation\n",
    "\n",
    "Steps to propagate biomass uncertainty through Monte Carlo simulation. Based on the proposal by Réjou-Méchain et al., 2017, Methods in Ecology and Evolution 8:1163-1167 and implemented in the R package *Biomass*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to propagate AGB uncertainty through Monte Carlo simulation.\n",
    "\n",
    "1. Model tree diameter error. Could be normal distribution, parameters fitted from quality control measurements.  \n",
    "\n",
    "2. Model wood density error. *Biomass* uses a truncated normal distribution based on the absolute ranges recorded at the wood density database (0.08-1.39 g/ml). A better way could be based on ancestral range reconstructed on a seed plant phylogeny. Our approach employs each tree assumed wood density (taxonomic info is not discarded as *Biomass* does) and generates a normal distribution of variance 0.07727873895528423, which is the mean variance recorded for species with multiple entries in the Global Wood Database.\n",
    "\n",
    "3. Tree height error. *Biomass* takes a truncated normal distribution with the range(1.3-(maximum_height + 15)). However, this kind of error seems to by exponentially distributed, as it is more likely to record wrong values with taller trees. Parameters could be fitted with quality control measurements.\n",
    "\n",
    "4. Allometric equation uncertainty. Depending on the allometric equation employed, coefficient distributions are estimated. *Biomass* estimates a posterior distribution for each equation using a MCMCMC.\n",
    "\n",
    "5. Above ground biomass estimates are simulated for each tree n times using all the parameter distributions presented above, plus a random error. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy as al\n",
    "import db_utils\n",
    "import comm\n",
    "import pymc3\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First section\n",
    "Bayesian inference of allometric equation coefficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load harvest data from Chave et al 2014\n",
    "har = pd.read_csv(\"../Chave_harvest_db/Chave_GCB_Direct_Harvest_Data.csv\")\n",
    "loc = pd.read_csv(\"../Chave_harvest_db/Localities.csv\")\n",
    "loc['Forest_type'] = loc.Forest_type.str.replace(' forest','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to estimate environmental E coefficient from Chave et al. 2014\n",
    "def est_E(row):\n",
    "    ts = loc[loc.Abbreviation == row.Site]['Temp_Seasonality'].item()\n",
    "    cwd = loc[loc.Abbreviation == row.Site]['CWD_mm_yr'].item()\n",
    "    ps = loc[loc.Abbreviation == row.Site]['Precip_Seasonality_perc'].item()\n",
    "    E = (0.178 * ts - 0.938 * cwd - 6.61 * ps) * 1e-3\n",
    "    return E\n",
    "\n",
    "har['E'] = har.apply(est_E, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian inference of allometric equation coefficients\n",
    "mymodel = pymc3.Model()\n",
    "trace = None\n",
    "with mymodel:\n",
    "    # Priors, all set to normal distributions\n",
    "    a = pymc3.Normal('a', mu = -2.109, sd = 0.5)\n",
    "    b = pymc3.Normal('b', mu = -0.896, sd = 0.5)\n",
    "    c = pymc3.Normal('c', mu = 0.923, sd = 0.5)\n",
    "    d = pymc3.Normal('d', mu = 2.794, sd = 0.5)\n",
    "    e = pymc3.Normal('e', mu = -0.046, sd = 0.5)\n",
    "    sigma = pymc3.HalfNormal('sigma', sd=1)\n",
    "    \n",
    "    # Allometric equation (Chave et al. 2014)\n",
    "    y_exp = a + b * har.E + c * np.log(har.Gravity) + d * np.log(har.DBH_cm) + e * \\\n",
    "        np.log(har.DBH_cm)**2   \n",
    "        \n",
    "    # Likelihood function: normal distribution\n",
    "    Y_obs = pymc3.Normal('Y_obs', mu=y_exp, sd=sigma, observed=np.log(har.AGB_kg))\n",
    "    \n",
    "    ###############################################################\n",
    "    # Metropolis kernel was the sampler employed by Réjou-Méchain et al. (2017), however \n",
    "    # here we use NUTS (No U-Turn Sampler), which achieves convergence faster\n",
    "    # In PYMC3 Nuts is the default sampler for continuous equation, like our case\n",
    "    ################################################################\n",
    "    \n",
    "    #mstep = pymc3.Metropolis()\n",
    "    #trace = pymc3.sample(50000, njobs=4, step=mstep)\n",
    "    \n",
    "    trace = pymc3.sample(5000, njobs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimates the effective population size of each parameter in the posterior distribution\n",
    "pymc3.diagnostics.effective_n(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prints out basic statistical parameters for each parameter\n",
    "pymc3.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the posterior distribution. Requires matplotlib.pyplot\n",
    "pymc3.traceplot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second section\n",
    "Estimation of diameter and density uncertainty from plot data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plot data from IFN database\n",
    "\n",
    "user = ''\n",
    "password = ''\n",
    "database = ''\n",
    "\n",
    "engine = al.create_engine(\n",
    "    'mysql+mysqldb://{0}:{1}@localhost/{2}?charset=utf8&use_unicode=1&unix_socket=/var/run/mysqld/mysqld.sock'.format(\n",
    "    user, password, database))\n",
    "\n",
    "conn = engine.connect()\n",
    "\n",
    "# Table of taxonomic equivalence. Contains two columns: Taxon ID and Accepted Taxon ID. \n",
    "accnames = db_utils.acctax(conn)\n",
    "\n",
    "# Simple table with all dasometric data, species names and densities.\n",
    "table = db_utils.dasotab('Quimera', conn, 1, accepted_taxa = accnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Paths to raster files\n",
    "#densities_file = '/home/nelsonsalinas/Documents/IDEAM/GlobalWoodDensityDB/gwddb_20180113.csv'\n",
    "densities_file = '/home/nelson/Documents/IDEAM/wood_density_db/ChaveDB/gwddb_20180113.csv'\n",
    "#elevation_raster = '/home/nelsonsalinas/Documents/IDEAM/cust_layers/alt.tif'\n",
    "elevation_raster = '/home/nelson/Documents/IDEAM/cust_layers/alt/alt.tif'\n",
    "#precipitation_raster = '/home/nelsonsalinas/Documents/IDEAM/cust_layers/precp.tif'\n",
    "precipitation_raster = '/home/nelson/Documents/IDEAM/cust_layers/precp/precp.tif'\n",
    "#chave_E_raster = '/home/nelsonsalinas/Documents/IDEAM/Chave_E/E.bil'\n",
    "chave_E_raster = '/home/nelson/Documents/IDEAM/Chave_cartography/E.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot data is handled through the Plot class. It contains several methods to procure \n",
    "# all the basic data require for iomass calculation (forest types, wood densities, \n",
    "# removal of herbaceus taxa, etc.). Check the source (`comm.py`) for further documentation.\n",
    "\n",
    "myplot = comm.Plot(dataframe=table)\n",
    "myplot.name = 1\n",
    "myplot.purify()\n",
    "myplot.coordinates = db_utils.coords('Quimera', conn, 100)\n",
    "myplot.set_holdridge(elevation_raster, precipitation_raster)\n",
    "myplot.set_chave_forest(precipitation_raster)\n",
    "myplot.set_E(chave_E_raster)\n",
    "myplot.densities_from_file(densities_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample tree diameter and wood density uncertainty values\n",
    "\n",
    "# Samples to draw from density and diameter distribution per tree\n",
    "iters = 100\n",
    "\n",
    "# Sample posterior distribution of parameters\n",
    "myas = np.random.choice(trace.get_values('a', burn = 1000, combine=True), iters)\n",
    "myas = np.append(myas, myas.mean())\n",
    "mybs = np.random.choice(trace.get_values('b', burn = 1000, combine=True), iters)\n",
    "mybs = np.append(mybs, mybs.mean())\n",
    "mycs = np.random.choice(trace.get_values('c', burn = 1000, combine=True), iters)\n",
    "mycs = np.append(mycs, mycs.mean())\n",
    "myds = np.random.choice(trace.get_values('d', burn = 1000, combine=True), iters)\n",
    "myds = np.append(myds, myds.mean())\n",
    "myes = np.random.choice(trace.get_values('e', burn = 1000, combine=True), iters)\n",
    "myes = np.append(myes, myes.mean())\n",
    "\n",
    "# Multidimensional array of simulated data. Each row contains the data simulated\n",
    "# for a single tree.\n",
    "AGB = []\n",
    "diamUnc = []\n",
    "wdUnc = []\n",
    "alloUnc = []\n",
    "\n",
    "\n",
    "for tree in myplot.stems.itertuples():\n",
    "    AGB.append([])\n",
    "    diamUnc.append([])\n",
    "    wdUnc.append([])\n",
    "    alloUnc.append([])\n",
    "    \n",
    "    # Diameter sampling\n",
    "    sdd = tree.Diameter / 20.0\n",
    "    diams = np.random.normal(tree.Diameter, sdd, iters)\n",
    "    diams = np.append(diams, tree.Diameter)\n",
    "\n",
    "    # Wood density sampling\n",
    "    wd = myplot.taxa[myplot.taxa.TaxonID == tree.TaxonID]['Density'].item()\n",
    "    sdwd = 0.07727873895528423\n",
    "    wds = np.random.normal(wd, sdwd, iters)\n",
    "    wds = np.append(wds, wd)\n",
    "\n",
    "    # Biomass sampling from simulated uncertainty ranges\n",
    "    for sdi, swd, sa, sb, sc, sd, se in zip(diams[:-1], wds[:-1], myas[:-1], mybs[:-1], \n",
    "                                            mycs[:-1], myds[:-1], myes[:-1]):\n",
    "        agb = sa + sb * myplot.E + sc * np.log(swd) + sd * np.log(sdi) + se * np.log(sdi)**2\n",
    "        AGB[-1].append(agb)\n",
    "    \n",
    "    # Uncertainty due to diameter error\n",
    "    for sdi in diams[:-1]:\n",
    "        agb = myas[-1] + mybs[-1] * myplot.E + mycs[-1] * np.log(wds[-1]) + myds[-1] * \\\n",
    "            np.log(sdi) + myes[-1] * np.log(sdi)**2\n",
    "        diamUnc[-1].append(agb)\n",
    "\n",
    "    # Uncertainty due to wood density error\n",
    "    for swd in wds[:-1]:\n",
    "        agb = myas[-1] + mybs[-1] * myplot.E + mycs[-1] * np.log(swd) + myds[-1] * \\\n",
    "            np.log(diams[-1]) + myes[-1] * np.log(diams[-1])**2\n",
    "        wdUnc[-1].append(agb)\n",
    "\n",
    "    # Uncertainty due to error of allometric equation coefficients\n",
    "    for sa, sb, sc, sd, se in zip(myas[:-1], mybs[:-1], mycs[:-1], myds[:-1], myes[:-1]):\n",
    "        agb = sa + sb * myplot.E + sc * np.log(wds[-1]) + sd * np.log(diams[-1]) + se * \\\n",
    "            np.log(diams[-1])**2\n",
    "        alloUnc[-1].append(agb)\n",
    "\n",
    "        \n",
    "AGB = np.array(AGB)\n",
    "diamUnc = np.array(diamUnc)\n",
    "wdUnc = np.array(wdUnc)\n",
    "alloUnc = np.array(alloUnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simulations to estimate plot AGB   \n",
    "path_sims = 10000\n",
    "\n",
    "total_agb = []\n",
    "for x in xrange(path_sims):\n",
    "    this_agb = 0.0\n",
    "    for t in xrange(AGB.shape[0]):\n",
    "        this_agb += np.random.choice(AGB[t], 1)\n",
    "    total_agb.append(this_agb[0])\n",
    "\n",
    "total_diam_unc = []\n",
    "for x in xrange(path_sims):\n",
    "    this_agb = 0.0\n",
    "    for t in xrange(diamUnc.shape[0]):\n",
    "        this_agb += np.random.choice(diamUnc[t], 1)\n",
    "    total_diam_unc.append(this_agb[0])\n",
    "\n",
    "total_wood_unc = []\n",
    "for x in xrange(path_sims):\n",
    "    this_agb = 0.0\n",
    "    for t in xrange(wdUnc.shape[0]):\n",
    "        this_agb += np.random.choice(wdUnc[t], 1)\n",
    "    total_wood_unc.append(this_agb[0])\n",
    "\n",
    "total_allo_unc = []\n",
    "for x in xrange(path_sims):\n",
    "    this_agb = 0.0\n",
    "    for t in xrange(alloUnc.shape[0]):\n",
    "        this_agb += np.random.choice(alloUnc[t], 1)\n",
    "    total_allo_unc.append(this_agb[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the final AGB distribution\n",
    "plt.hist(total_agb, bins=100)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(total_diam_unc, bins=100)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(total_wood_unc, bins=100)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(total_allo_unc, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"AGB distribution:\\n\",describe(total_agb)\n",
    "print \"\\nUncertainty due to diameter error:\\n\",describe(total_diam_unc)\n",
    "print \"\\nUncertainty due to wood density error:\\n\",describe(total_wood_unc)\n",
    "print \"\\nUncertainty due to allometric equation error:\\n\",describe(total_allo_unc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
