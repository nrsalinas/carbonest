{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allometric equation uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import allometry\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Site', u'DBH_cm', u'Total_height_m', u'AGB_kg', u'Gravity'], dtype='object')\n",
      "Index([u'Abbreviation', u'Tree_count', u'2005_avail', u'Latitude',\n",
      "       u'Longitude', u'Locality', u'Forest_type', u'Successional_type',\n",
      "       u'Mean_annual_temperature', u'Temp_Seasonality', u'Mean_Annual_Precip',\n",
      "       u'Precip_Seasonality_perc', u'Altitude', u'Evapotranspiration_mm_yr',\n",
      "       u'Dry_months', u'CWD_mm_yr', u'Ref'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load harvest data from Chave et al 2014\n",
    "har = pd.read_csv(\"../Chave_harvest_db/Chave_GCB_Direct_Harvest_Data.csv\")\n",
    "loc = pd.read_csv(\"../Chave_harvest_db/Localities.csv\")\n",
    "loc['Forest_type'] = loc.Forest_type.str.replace(' forest','')\n",
    "print har.columns\n",
    "print loc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allometric functions\n",
    "def est_chaveI(row):\n",
    "    fo = loc[loc.Abbreviation == row.Site]['Forest_type'].item()\n",
    "    return allometry.chaveI(row.DBH_cm, row.Gravity, fo)\n",
    "\n",
    "def est_chaveI_or(row):\n",
    "    fo = loc[loc.Abbreviation == row.Site]['Forest_type'].item()\n",
    "    return allometry.chaveI_original(row.DBH_cm, row.Gravity, fo)\n",
    "\n",
    "def est_E(row):\n",
    "    #E = ( 0.178 × TS-0.938 × CWD-6.61× PS ) ×10 −3\n",
    "    ts = loc[loc.Abbreviation == row.Site]['Temp_Seasonality'].item()\n",
    "    cwd = loc[loc.Abbreviation == row.Site]['CWD_mm_yr'].item()\n",
    "    ps = loc[loc.Abbreviation == row.Site]['Precip_Seasonality_perc'].item()\n",
    "    E = (0.178 * ts - 0.938 * cwd - 6.61 * ps) * 1e-3\n",
    "    return E\n",
    "\n",
    "def est_chaveII(row):\n",
    "    return allometry.chaveII(row.DBH_cm, row.Gravity, e_value = row.E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "har['E'] = har.apply(est_E, axis=1)\n",
    "har['ChaveI'] = har.apply(est_chaveI, axis=1)\n",
    "har['ChaveI_or'] = har.apply(est_chaveI_or, axis=1)\n",
    "har['ChaveII'] = har.apply(est_chaveII, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Estimate errors\n",
    "har['ChaveI_error'] = (np.log(har.ChaveI) - np.log(har.AGB_kg))**2\n",
    "har['ChaveI_or_error'] = (np.log(har.ChaveI_or) - np.log(har.AGB_kg))**2\n",
    "har['ChaveII_error'] = (np.log(har.ChaveII) - np.log(har.AGB_kg))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.597036288929\n",
      "0.57808567889\n",
      "0.420779217764\n"
     ]
    }
   ],
   "source": [
    "# SEEs\n",
    "print (har.ChaveI_error.sum() / (har.shape[0]-4))**0.5\n",
    "print (har.ChaveI_or_error.sum() / (har.shape[0]-4))**0.5\n",
    "print (har.ChaveII_error.sum() / (har.shape[0]-5))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fitting function coefficients from scratch\n",
    "\n",
    "def chave2005(X, a, b, c, d):\n",
    "    dap, den = X\n",
    "    out = a + b * np.log(dap) + c * np.log(dap)**2 + d * np.log(dap)**3 + np.log(den)\n",
    "    return out\n",
    "\n",
    "def chave2014(X, a, b, c, d, e):\n",
    "    E, den, dap = X\n",
    "    out = a + b * E + c * np.log(den) + d * np.log(dap) + e * np.log(dap)**2\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-3.35030644,  3.68832942, -0.29566994,  0.02574888]),\n",
       " array([[ 0.12942566, -0.13359906,  0.04347523, -0.00448497],\n",
       "        [-0.13359906,  0.13954395, -0.04588297,  0.00477556],\n",
       "        [ 0.04347523, -0.04588297,  0.01523812, -0.00160049],\n",
       "        [-0.00448497,  0.00477556, -0.00160049,  0.00016959]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curve_fit(chave2005, (har.DBH_cm, har.Gravity), np.log(har.AGB_kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.526537644398\n"
     ]
    }
   ],
   "source": [
    "har['ChaveI_new'] = np.exp(chave2005((har.DBH_cm, har.Gravity), -3.350, 3.688, -0.296, 0.026))\n",
    "har['ChaveI_new_error'] = (np.log(har.ChaveI_new) - np.log(har.AGB_kg))**2\n",
    "print (har.ChaveI_new_error.sum() / (har.shape[0]-4)) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-2.10942259, -0.89647401,  0.92284733,  2.79430146, -0.04585078]),\n",
       " array([[  6.98923097e-03,  -2.73651475e-04,   2.46197208e-04,\n",
       "          -4.58184091e-03,   7.17341406e-04],\n",
       "        [ -2.73651475e-04,   3.65234170e-04,  -1.09504322e-04,\n",
       "           6.04247529e-05,  -2.83776447e-06],\n",
       "        [  2.46197208e-04,  -1.09504322e-04,   5.41010476e-04,\n",
       "           1.22203572e-05,   1.06427576e-06],\n",
       "        [ -4.58184091e-03,   6.04247529e-05,   1.22203572e-05,\n",
       "           3.16582330e-03,  -5.07408790e-04],\n",
       "        [  7.17341406e-04,  -2.83776447e-06,   1.06427576e-06,\n",
       "          -5.07408790e-04,   8.33124928e-05]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curve_fit(chave2014, (har.E, har.Gravity, har.DBH_cm), np.log(har.AGB_kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.415318493142\n"
     ]
    }
   ],
   "source": [
    "har['ChaveII_new'] = np.exp(chave2014((har.E, har.Gravity, har.DBH_cm), -2.109, -0.896,  0.923,  2.794, -0.046))\n",
    "har['ChaveII_new_error'] = (np.log(har.ChaveII_new) - np.log(har.AGB_kg))**2\n",
    "print (har.ChaveII_new_error.sum() / (har.shape[0]-5)) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum likelihood fit - Spicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logLike(true, guess):\n",
    "    n = len(true)\n",
    "    error = true - guess\n",
    "    sigma = np.std(error)\n",
    "    f = -(n/2.0)*np.log(2*np.pi) - (n/2.0) * np.log(sigma**2) - \\\n",
    "            (1.0/(2*sigma**2) * np.dot(error.T,error))\n",
    "    return f\n",
    "\n",
    "def opt_chave2005(pars):\n",
    "    y = pars[0] + pars[1] * np.log(har.DBH_cm) + pars[2] * np.log(har.DBH_cm)**2 + \\\n",
    "            pars[3] * np.log(har.DBH_cm)**3 + np.log(har.Gravity)\n",
    "    log = logLike(np.log(har.AGB_kg), y)\n",
    "    return -1 * log\n",
    "\n",
    "def opt_chave2014(pars):\n",
    "    y = pars[0] + pars[1] * har.E + pars[2] * np.log(har.Gravity) + pars[3] * np.log(har.DBH_cm) \\\n",
    "        + pars[4] * np.log(har.DBH_cm)**2 \n",
    "    log = logLike(np.log(har.AGB_kg), y)\n",
    "    return -1 * log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chave 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coeffs = np.array([-3.350, 3.688, -0.296, 0.026])\n",
    "coeffs = np.array([-2.350, 2.688, -1.296, 0.026])\n",
    "#opt_chave2005(coeffs)\n",
    "res = minimize(opt_chave2005, coeffs, method='BFGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 3110.9083213173753\n",
       " hess_inv: array([[ 0.13983882, -0.14478274,  0.04725636, -0.00488957],\n",
       "       [-0.14478274,  0.15184922, -0.05013124,  0.00523845],\n",
       "       [ 0.04725636, -0.05013124,  0.01673074, -0.00176555],\n",
       "       [-0.00488957,  0.00523845, -0.00176555,  0.00018807]])\n",
       "      jac: array([-0.00506592, -0.0043335 , -0.00579834, -0.01083374])\n",
       "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
       "     nfev: 425\n",
       "      nit: 18\n",
       "     njev: 69\n",
       "   status: 2\n",
       "  success: False\n",
       "        x: array([-3.35027032,  3.68827668, -0.29564789,  0.02574613])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chave 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coeffs = np.array([-2.109, -0.896,  0.923,  2.794, -0.046])\n",
    "coeffs = np.array([-3.109, -1.896,  1.923,  1.794, 1.046])\n",
    "res = minimize(opt_chave2014, coeffs, method='BFGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 2160.528919892148\n",
       " hess_inv: array([[  3.85710046e-03,   1.09729450e-03,   1.07812261e-03,\n",
       "         -3.09214706e-03,   5.84385688e-04],\n",
       "       [  1.09729450e-03,   4.23187321e-04,   7.68583429e-05,\n",
       "         -9.49080921e-04,   1.74061446e-04],\n",
       "       [  1.07812261e-03,   7.68583429e-05,   7.87634297e-04,\n",
       "         -6.84315569e-04,   1.36771250e-04],\n",
       "       [ -3.09214706e-03,  -9.49080921e-04,  -6.84315569e-04,\n",
       "          2.65421608e-03,  -5.09667353e-04],\n",
       "       [  5.84385688e-04,   1.74061446e-04,   1.36771250e-04,\n",
       "         -5.09667353e-04,   9.94911498e-05]])\n",
       "      jac: array([ -6.10351562e-05,   6.10351562e-05,   6.10351562e-05,\n",
       "        -6.10351562e-05,   3.05175781e-05])\n",
       "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
       "     nfev: 288\n",
       "      nit: 21\n",
       "     njev: 41\n",
       "   status: 2\n",
       "  success: False\n",
       "        x: array([-2.10942915, -0.896474  ,  0.92284721,  2.79430614, -0.04585156])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum likelihood fit\n",
    "### equation Chave I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = pymc3.Model()\n",
    "with mymodel:\n",
    "    #a + b * np.log(dap) + c * np.log(dap)**2 + d * np.log(dap)**3 + np.log(den)\n",
    "    a = pymc3.Uniform('a')\n",
    "    b = pymc3.Uniform('b')\n",
    "    c = pymc3.Uniform('c')\n",
    "    d = pymc3.Uniform('d')\n",
    "    #sigma = pymc3.Normal('sigma', mu=0, sd=0.4)\n",
    "    \n",
    "    y_exp = a + b * np.log(har.DBH_cm) + c * np.log(har.DBH_cm)**2 + d * np.log(har.DBH_cm)**3 + \\\n",
    "        np.log(har.Gravity)\n",
    "        \n",
    "    Y_obs = pymc3.Normal('Y_obs', mu=y_exp, sd=0.4, observed=np.log(har.AGB_kg))\n",
    "    \n",
    "    trace = pymc3.sample(5000, njobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymc3.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_estimate = pymc3.find_MAP(model=mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_estimate\n",
    "# 0.1606, 1, 0.262888, 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum likelihood fit\n",
    "### equation Chave II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = pymc3.Model()\n",
    "with mymodel:\n",
    "    #a + b * E + c * np.log(den) + d * np.log(dap) + e * np.log(dap)**2\n",
    "    a = pymc3.Uniform('a')\n",
    "    b = pymc3.Uniform('b')\n",
    "    c = pymc3.Uniform('c')\n",
    "    d = pymc3.Uniform('d')\n",
    "    e = pymc3.Uniform('e')\n",
    "    sigma = pymc3.HalfNormal('sigma', sd=1)\n",
    "    \n",
    "    y_exp = a + b * har.E + c * np.log(har.Gravity) + d * np.log(har.DBH_cm) + e * np.log(har.DBH_cm)**2   \n",
    "        \n",
    "    Y_obs = pymc3.Normal('Y_obs', mu=y_exp, sd=sigma, observed=np.log(har.AGB_kg))\n",
    "    \n",
    "    trace = pymc3.sample(5000, njobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymc3.diagnostics.effective_n(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pymc3.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_estimate = pymc3.find_MAP(model=mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_estimate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
